{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2023 CITS4012 Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please check the bottom of the this ipynb file*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) \n",
        "\n",
        "Import necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/finnmurphy/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the train and test data and save them as pandas data frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('WikiQA-train.tsv', sep='\\t')\n",
        "test_data = pd.read_csv('WikiQA-test.tsv', sep='\\t')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the unique questions from the train and test data frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_questions(data):\n",
        "    return data['Question'].unique().tolist()\n",
        "\n",
        "train_questions = get_questions(train_data)\n",
        "test_questions = get_questions(test_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the answers corresponding to each question from the train and test data frames. If an answer does not exist for a particular question, then an empty string will be added to the answer list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_answers(data, questions):\n",
        "    answers = []\n",
        "    for question in questions:\n",
        "        df = data[data['Question'] == question]\n",
        "        index = df.loc[df['Label'] == 1]['Sentence'].index.values\n",
        "        if len(index) == 0:\n",
        "            answers.append('')\n",
        "        else:\n",
        "            answers.append(df.loc[index[0], \"Sentence\"])\n",
        "    return answers\n",
        "\n",
        "train_answers = get_answers(train_data, train_questions)\n",
        "test_answers = get_answers(test_data, test_questions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the documents corresponding to each question by joining the sentences. Make sure each sentence is seperated by a whitespace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_documents(data, questions):\n",
        "    documents = []\n",
        "    for question in questions:\n",
        "        df = data[data['Question'] == question]\n",
        "        sentences = df['Sentence'].tolist()\n",
        "        for i in range(0, len(sentences) - 1):\n",
        "            sentences[i] = sentences[i] + ' '\n",
        "        documents.append(''.join(sentences))\n",
        "    return documents\n",
        "\n",
        "train_documents = get_documents(train_data, train_questions)\n",
        "test_documents = get_documents(test_data, test_questions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenize documents and label tokens as: Start Token of the Answer (S), Inner Token of the Answer (I), End Token of the Answer (E) or None (N). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_documents(documents, answers):\n",
        "    tagged_documents = []\n",
        "    for i in range(len(documents)):\n",
        "        tagged_document = []\n",
        "        answer = answers[i]\n",
        "        document = documents[i]\n",
        "        if answer == '':\n",
        "            tokens = word_tokenize(document)\n",
        "            for j in range(len(tokens)):\n",
        "                tagged_document.append('N')\n",
        "        else:\n",
        "            parts = document.partition(answer)\n",
        "            for j in range(len(parts)):\n",
        "                tokens = word_tokenize(parts[j])\n",
        "                if j == 1:\n",
        "                    tagged_document.append('S')\n",
        "                    for k in range(len(tokens) - 2):\n",
        "                        tagged_document.append('I')\n",
        "                    tagged_document.append('E')\n",
        "                else:\n",
        "                    for k in range(len(tokens)):\n",
        "                        tagged_document.append('N')\n",
        "            tagged_documents.append(tagged_document)\n",
        "    return tagged_documents\n",
        "\n",
        "train_labeled_documents = label_documents(train_documents, train_answers)\n",
        "test_labeled_documents = label_documents(test_documents, test_answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2.QA Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Model Testing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cTNGfO0h9I3W"
      },
      "source": [
        "### 3.1. Input Embedding Ablation Study\n",
        "\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEVsyvrc9VHL"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uX7nFwMo9WBE"
      },
      "source": [
        "### 3.2. Attention Ablation Study\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfRK-BeiNSVi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0VAR8GF9hSD"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "llzGjUe6NDnB"
      },
      "source": [
        "### 3.3. Hyper Parameter Testing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xj4PNyrNDBH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
