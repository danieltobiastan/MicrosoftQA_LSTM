{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "32yCsRUo8H33"
   },
   "source": [
    "# 2023 CITS4012 Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XCybYoGz8YWQ"
   },
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.* \n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please check the bottom of the this ipynb file*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6po98qVA8bJD"
   },
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "train_data = pd.read_csv(\"WikiQA-train.tsv\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"WikiQA-test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the unique questions from the train and test data frames, including the documentID and the DocumentTitle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_documenttag(data):\n",
    "    qd = data[\n",
    "        [\"Question\", \"QuestionID\", \"DocumentID\", \"DocumentTitle\"]\n",
    "    ].drop_duplicates()\n",
    "    return qd\n",
    "\n",
    "train_question_doctag = get_questions_documenttag(train_data)\n",
    "test_question_doctag = get_questions_documenttag(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique questions\n",
    "train_questions = train_question_doctag[\"Question\"]\n",
    "test_questions = test_question_doctag[\"Question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique document ids\n",
    "train_docid = train_question_doctag[\"DocumentID\"]\n",
    "test_docid = test_question_doctag[\"DocumentID\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the answers to those questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(data, questions, documentids):\n",
    "    answers = []  # list of answers\n",
    "    for q in range(len(questions)):\n",
    "        question = questions.iloc[q]\n",
    "        doc_id = documentids.iloc[q]  # add the document id\n",
    "        df = data[data[\"Question\"] == question]\n",
    "        index = df.loc[df[\"Label\"] == 1][\"Sentence\"].index.values\n",
    "        if len(index) == 0:  # if no answer found\n",
    "            answers.append([question, doc_id, \"No answer\"])\n",
    "        else:  # if 1 answer found\n",
    "            answers.append([question, doc_id, df.loc[index[0], \"Sentence\"]])\n",
    "    return answers\n",
    "\n",
    "train_answers = pd.DataFrame(get_answers(train_data, train_questions, train_docid))\n",
    "test_answers = pd.DataFrame(get_answers(test_data, test_questions, test_docid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above get_answers returns train_answers and test_answers which, gives us in the following columns\n",
    "\n",
    "-   Question\n",
    "-   Related Document ID\n",
    "-   Answer (if no answer to that question, return no answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(data, questions, documentids):  # (done by Finn, tweaked by Dan)\n",
    "    documents = []\n",
    "    for q in range(len(questions)):\n",
    "        question = questions.iloc[q]\n",
    "        doc_id = documentids.iloc[q]  # add the document id\n",
    "        df = data[data[\"Question\"] == question]\n",
    "        sentences = df[\"Sentence\"].tolist()\n",
    "        for i in range(0, len(sentences) - 1):\n",
    "            sentences[i] = sentences[i] + \" \"\n",
    "        documents.append([doc_id, \"\".join(sentences)])\n",
    "    return documents\n",
    "\n",
    "# return the individual document in list\n",
    "train_documents = pd.DataFrame(get_documents(train_data, train_questions, train_docid))  \n",
    "# return the individual document in list\n",
    "test_documents = pd.DataFrame(get_documents(test_data, test_questions, test_docid))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above train_documents and test_documents called from the get_documents gives us in the following columns\n",
    "\n",
    "-   Document ID\n",
    "-   Full Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming all the columns for more standardised access\n",
    "train_answers.columns = [\"Question\", \"DocumentID\", \"Answer\"]\n",
    "test_answers.columns = [\"Question\", \"DocumentID\", \"Answer\"]\n",
    "train_documents.columns = [\"DocumentID\", \"Document\"]\n",
    "test_documents.columns = [\"DocumentID\", \"Document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result is 2117, 2117, 630, 630\n",
    "len(train_answers), len(train_documents), len(test_answers), len(test_documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior to tagging, we should maybe clean the document and answers first:** (stopped here)\n",
    "\n",
    "Maybe?\n",
    "\n",
    "-   lowercase (might lose context, but we can use on questions)\n",
    "-   removing any punctuation or weird symbols (do)\n",
    "-   removal of stop words? (probably not)\n",
    "\n",
    "Make sure that the pre-processing is standardised to be the same throughout doc and ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lower(text):\n",
    "    # Lowercase the text for question, answer and documents\n",
    "    text = text.lower()\n",
    "    pattern = r\"[^a-zA-Z0-9\\s]\"\n",
    "    cleaned_text = re.sub(pattern, \" \", text)\n",
    "    return cleaned_text\n",
    "\n",
    "train_answers[[\"Question\", \"Answer\"]] = train_answers[[\"Question\", \"Answer\"]].applymap(preprocess_lower)\n",
    "train_documents[\"Document\"] = train_documents[\"Document\"].apply(preprocess_lower)\n",
    "test_answers[[\"Question\", \"Answer\"]] = test_answers[[\"Question\", \"Answer\"]].applymap(preprocess_lower)\n",
    "test_documents[\"Document\"] = test_documents[\"Document\"].apply(preprocess_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(documents, answers):\n",
    "    tagged_documents = []\n",
    "    for q in range(len(answers)):\n",
    "        tagged_document = []\n",
    "        qn = answers[\"Question\"].loc[q]\n",
    "        doc_id = answers[\"DocumentID\"].loc[q]\n",
    "        content = documents.loc[documents[\"DocumentID\"] == doc_id, \"Document\"].values[0]\n",
    "        answer = answers[\"Answer\"].loc[q]\n",
    "\n",
    "        if answer == \"no answer\":\n",
    "            tokens = word_tokenize(content)\n",
    "            for j in range(len(tokens)):\n",
    "                tagged_document.append(\"N\")  # none\n",
    "        else:\n",
    "            parts = content.partition(answer)\n",
    "            for j in range(len(parts)):\n",
    "                tokens = word_tokenize(parts[j])\n",
    "                if j == 1:\n",
    "                    tagged_document.append(\"S\")  # start of answer\n",
    "                    for k in range(len(tokens) - 2):\n",
    "                        tagged_document.append(\"I\")  # inside of answer\n",
    "                    tagged_document.append(\"E\")  # end of answer\n",
    "                else:\n",
    "                    for k in range(len(tokens)):\n",
    "                        tagged_document.append(\"N\")  # outside answer\n",
    "        tagged_documents.append(tagged_document)\n",
    "    return tagged_documents\n",
    "\n",
    "train_doc_ans_labels = labelling(train_documents, train_answers)\n",
    "test_doc_ans_labels = labelling(test_documents, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tags are good\n",
    "def testing_tokens(ind, labels, documents, answers):\n",
    "    for i, j in zip(labels[ind], word_tokenize(documents[\"Document\"][ind])):\n",
    "        print([i, j])\n",
    "    print(answers[\"Answer\"][ind])\n",
    "\n",
    "testing_tokens(100, train_doc_ans_labels, train_documents, train_answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned Documents: train and test\n",
    "\n",
    "train_answers - contains the ['Question','DocumentID','Answer']\n",
    "\n",
    "train_documents - contains the ['DocumentID','Document']\n",
    "\n",
    "train_doc_ans_labels - contains a list of list of answer tags for each document,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare the document for word embeddings:\n",
    "train_doc_ques = pd.DataFrame({\n",
    "    \"Document\": train_documents[\"Document\"], \n",
    "    \"Question\": train_answers[\"Question\"]\n",
    "})\n",
    "test_doc_ques = pd.DataFrame({\n",
    "    \"Document\": test_documents[\"Document\"], \n",
    "    \"Question\": test_answers[\"Question\"]\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.QA Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "To use the CBOW model, we need the data in sentences. Extract this from the original dataset, don't use sent_tokenise, will mess with some of the fullstops, we want to maintain structure from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokens(data):\n",
    "    sentence_list = []\n",
    "    for i in range(len(data)):\n",
    "        sentence_list.append(word_tokenize(data[i]))\n",
    "    return sentence_list\n",
    "\n",
    "train_doc_list = word_tokens(train_doc_ques[\"Document\"])\n",
    "train_ques_list = word_tokens(train_doc_ques[\"Question\"])\n",
    "test_doc_list = word_tokens(test_doc_ques[\"Document\"])\n",
    "test_ques_list = word_tokens(test_doc_ques[\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = train_doc_list + train_ques_list + test_doc_list + test_ques_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trained, don't have to run this multiple times\n",
    "wc_cbow_model = Word2Vec(\n",
    "    sentences=combined_text,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=2,\n",
    "    epochs=30,\n",
    ")\n",
    "wc_cbow_model.save(\"cbow.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement QA\n",
    "\n",
    "1. Word Embeddings, using CBOW\n",
    "2. Feature Extraction 1 - POS tags\n",
    "3. Feature Extraction 2 - TF-IDF\n",
    "4. Feature Extraction 3 - NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(doc):\n",
    "    tokenized_doc = word_tokenize(doc)\n",
    "    embeddings = [wc_cbow_model.wv[word] for word in tokenized_doc]\n",
    "    return embeddings\n",
    "\n",
    "train_doc_ques[\"Doc_Embeddings\"] = train_doc_ques[\"Document\"].apply(get_word_embeddings)\n",
    "train_doc_ques[\"Q_Embeddings\"] = train_doc_ques[\"Question\"].apply(get_word_embeddings)\n",
    "test_doc_ques[\"Doc_Embeddings\"] = test_doc_ques[\"Document\"].apply(get_word_embeddings)\n",
    "test_doc_ques[\"Q_Embeddings\"] = test_doc_ques[\"Question\"].apply(get_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ques[\"Doc_Tokens\"] = train_doc_ques[\"Document\"].apply(word_tokenize)\n",
    "train_doc_ques[\"Q_Tokens\"] = train_doc_ques[\"Question\"].apply(word_tokenize)\n",
    "test_doc_ques[\"Doc_Tokens\"] = test_doc_ques[\"Document\"].apply(word_tokenize)\n",
    "test_doc_ques[\"Q_Tokens\"] = test_doc_ques[\"Question\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_count(doc):\n",
    "    count = 0\n",
    "    for i in range(len(doc)):\n",
    "        if len(doc[\"Doc_Embeddings\"][i]) != len(doc[\"Doc_Tokens\"][i]):\n",
    "            count += 1\n",
    "        elif len(doc[\"Q_Embeddings\"][i]) != len(doc[\"Q_Tokens\"][i]):\n",
    "            count += 1\n",
    "        else:\n",
    "            continue\n",
    "    return count\n",
    "\n",
    "check_count(train_doc_ques)  # looks good"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, need to convert the POS tags, NER tags into embeddings. After this, pad the questions and answers to the max question/document length in the combined training and test set.\n",
    "\n",
    "### PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pos tags to the tokens\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# download the dependency and resource as required\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "train_doc_ques[\"Doc_POS\"] = train_doc_ques[\"Doc_Tokens\"].apply(pos_tag)\n",
    "train_doc_ques[\"Q_POS\"] = train_doc_ques[\"Q_Tokens\"].apply(pos_tag)\n",
    "test_doc_ques[\"Doc_POS\"] = test_doc_ques[\"Doc_Tokens\"].apply(pos_tag)\n",
    "test_doc_ques[\"Q_POS\"] = test_doc_ques[\"Q_Tokens\"].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the POS tags: # looks ok\n",
    "test_doc_ques[\"Q_POS\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique POS Tags\n",
    "all_pos_tags = (\n",
    "    train_doc_ques[\"Doc_POS\"].tolist()\n",
    "    + test_doc_ques[\"Doc_POS\"].tolist()\n",
    "    + train_doc_ques[\"Q_POS\"].tolist()\n",
    "    + test_doc_ques[\"Q_POS\"].tolist()\n",
    ")\n",
    "\n",
    "def get_unique_pos(data):\n",
    "    pos_tags = set()\n",
    "    for item in data:\n",
    "        for _, pos_tag in item:\n",
    "            pos_tags.add(pos_tag)\n",
    "\n",
    "    pos_tag_index = {tag: i for i, tag in enumerate(sorted(pos_tags))}\n",
    "    return pos_tag_index\n",
    "\n",
    "pos_iden = get_unique_pos(all_pos_tags)  # list of tags\n",
    "pos_iden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagging\n",
    "\n",
    "#### Steps to run this:\n",
    "\n",
    "-   pip install spacy\n",
    "-   python -m spacy download en_core_web_sm\n",
    "\n",
    "If loaded for the first time, restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk using Spacy\n",
    "# pip install -U spacy\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# loading pre-trained model of NER\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tagging(texts):\n",
    "    tagged_texts = []\n",
    "    for text in texts:\n",
    "        doc = spacy.tokens.Doc(nlp.vocab, words=text)\n",
    "        nlp.get_pipe(\"ner\")(doc)\n",
    "        tagged_texts.append([(token.text, token.ent_type_) for token in doc])\n",
    "    return tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take a while...\n",
    "train_doc_ques[\"Doc_NER\"] = ner_tagging(train_doc_ques[\"Doc_Tokens\"])\n",
    "train_doc_ques[\"Q_NER\"] = ner_tagging(train_doc_ques[\"Q_Tokens\"])\n",
    "test_doc_ques[\"Doc_NER\"] = ner_tagging(test_doc_ques[\"Doc_Tokens\"])\n",
    "test_doc_ques[\"Q_NER\"] = ner_tagging(test_doc_ques[\"Q_Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar approach to the POS\n",
    "\n",
    "# Extract all unique POS Tags\n",
    "all_ner_tags = (\n",
    "    train_doc_ques[\"Doc_NER\"].tolist()\n",
    "    + test_doc_ques[\"Doc_NER\"].tolist()\n",
    "    + train_doc_ques[\"Q_NER\"].tolist()\n",
    "    + test_doc_ques[\"Q_NER\"].tolist()\n",
    ")\n",
    "\n",
    "def get_unique_ner(data):\n",
    "    ner_tags = set()\n",
    "    for item in data:\n",
    "        for _, ner_tag in item:\n",
    "            ner_tags.add(ner_tag)\n",
    "\n",
    "    ner_tag_index = {tag: i for i, tag in enumerate(sorted(ner_tags))}\n",
    "    return ner_tag_index\n",
    "\n",
    "ner_iden = get_unique_pos(all_ner_tags)  # list of tags\n",
    "ner_iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ohv dims\n",
    "ner_idx = ner_iden.values()\n",
    "aa = np.eye(max(ner_idx) + 1)\n",
    "# aa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "First, calculate the document frequency of each token in the entire corpus (training documents + testing documents). The result is a dictionary where each token is a key and its value is the document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(corpus):\n",
    "    \"\"\"\n",
    "    Computes the document frequency for every token in the corpus.\n",
    "    Returns a dictionary {token: doc_freq, ...}\n",
    "    \"\"\"\n",
    "    document_frequency = {}\n",
    "    for document in corpus:\n",
    "        for token in np.unique(document):\n",
    "            try:\n",
    "                document_frequency[token] += 1\n",
    "            except:\n",
    "                document_frequency[token] = 1\n",
    "    return document_frequency\n",
    "\n",
    "\n",
    "train_corpus = (\n",
    "    train_doc_ques[\"Doc_Tokens\"].tolist() + train_doc_ques[\"Q_Tokens\"].tolist()\n",
    ")\n",
    "test_corpus = test_doc_ques[\"Doc_Tokens\"].tolist() + test_doc_ques[\"Q_Tokens\"].tolist()\n",
    "train_doc_freq = document_frequency(train_corpus)\n",
    "test_doc_freq = document_frequency(test_corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate TF-IDF using the document frequency from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def compute_tf_idf(corpus, doc_frequency):\n",
    "    \"\"\"\n",
    "    Computes the term frequency inverse document frequency for every token in every document in the corpus.\n",
    "    Returns a list the same shape as the list of tokenized documents except every token is replaced with the tf-idf\n",
    "    for that token.\n",
    "    \"\"\"\n",
    "    tf_idf = {}\n",
    "    tf_idf_list = []\n",
    "    N = len(doc_frequency)\n",
    "    doc_id = 0\n",
    "    for document in corpus:\n",
    "        tf_idf_doc = []\n",
    "        counter = Counter(document)\n",
    "        total_num_words = len(document)\n",
    "        for token in np.unique(document):\n",
    "            tf = counter[token] / total_num_words\n",
    "            df = doc_frequency[token]\n",
    "            idf = math.log(N / (df + 1)) + 1\n",
    "            tf_idf[doc_id, token] = tf * idf\n",
    "        for token in document:\n",
    "            tf_idf_doc.append(tf_idf[doc_id, token])\n",
    "        tf_idf_list.append(tf_idf_doc)\n",
    "        doc_id += 1\n",
    "    return tf_idf_list\n",
    "\n",
    "\n",
    "train_doc_ques[\"Doc_TFIDF\"] = compute_tf_idf(train_doc_ques[\"Doc_Tokens\"].tolist(), train_doc_freq)\n",
    "train_doc_ques[\"Q_TFIDF\"] = compute_tf_idf(train_doc_ques[\"Q_Tokens\"].tolist(), train_doc_freq)\n",
    "test_doc_ques[\"Doc_TFIDF\"] = compute_tf_idf(test_doc_ques[\"Doc_Tokens\"].tolist(), test_doc_freq)\n",
    "test_doc_ques[\"Q_TFIDF\"] = compute_tf_idf(test_doc_ques[\"Q_Tokens\"].tolist(), test_doc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vectorize(pos_tagger, ner_tagger, data):  # pass in the unique dict for ner or pos\n",
    "    pos_idx = pos_tagger.values()\n",
    "    pos_ohv = np.eye(max(pos_idx) + 1)  # create the ohv\n",
    "    ner_idx = ner_tagger.values()\n",
    "    ner_ohv = np.eye(max(ner_idx) + 1)\n",
    "\n",
    "    dpos_full_ohv, dner_full_ohv = [], []  # lists to append to\n",
    "    qpos_full_ohv, qner_full_ohv = [], []  # lists to append to\n",
    "\n",
    "    for item in data[\"Doc_POS\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            pos_index_iden = pos_tagger[tag]\n",
    "            sent_ohv.append(pos_ohv[pos_index_iden])\n",
    "        dpos_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Q_POS\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            pos_index_iden = pos_tagger[tag]\n",
    "            sent_ohv.append(pos_ohv[pos_index_iden])\n",
    "        qpos_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Doc_NER\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            ner_index_iden = ner_tagger[tag]\n",
    "            sent_ohv.append(ner_ohv[ner_index_iden])\n",
    "        dner_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Q_NER\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            ner_index_iden = ner_tagger[tag]\n",
    "            sent_ohv.append(ner_ohv[ner_index_iden])\n",
    "        qner_full_ohv.append(sent_ohv)\n",
    "\n",
    "    return (dpos_full_ohv, qpos_full_ohv, dner_full_ohv, qner_full_ohv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ohv for doc\n",
    "(\n",
    "    train_doc_pos_ohv,\n",
    "    train_q_pos_ohv,\n",
    "    train_doc_ner_ohv,\n",
    "    train_q_ner_ohv,\n",
    ") = one_hot_vectorize(pos_iden, ner_iden, train_doc_ques)\n",
    "test_doc_pos_ohv, test_q_pos_ohv, test_doc_ner_ohv, test_q_ner_ohv = one_hot_vectorize(\n",
    "    pos_iden, ner_iden, test_doc_ques\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ques[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_doc_ques[\"Document\"].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dataframe to just tokens and embeddings:\n",
    "doc_emb_train = train_doc_ques[[\"Doc_Tokens\", \"Doc_Embeddings\", \"Doc_TFIDF\"]]\n",
    "doc_pos_ner = pd.DataFrame({\"Doc_POS\": train_doc_pos_ohv, \"Doc_NER\": train_doc_ner_ohv})\n",
    "doc_emb_train = pd.concat([doc_emb_train, doc_pos_ner], axis=1)\n",
    "\n",
    "q_emb_train = train_doc_ques[[\"Q_Tokens\", \"Q_Embeddings\", \"Q_TFIDF\"]]\n",
    "q_pos_ner = pd.DataFrame({\"Q_POS\": train_q_pos_ohv, \"Q_NER\": train_q_ner_ohv})\n",
    "q_emb_train = pd.concat([q_emb_train, q_pos_ner], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb_test = test_doc_ques[[\"Doc_Tokens\", \"Doc_Embeddings\", \"Doc_TFIDF\"]]\n",
    "doc_pos_ner = pd.DataFrame({\"Doc_POS\": test_doc_pos_ohv, \"Doc_NER\": test_doc_ner_ohv})\n",
    "doc_emb_test = pd.concat([doc_emb_test, doc_pos_ner], axis=1)\n",
    "\n",
    "q_emb_test = test_doc_ques[[\"Q_Tokens\", \"Q_Embeddings\", \"Q_TFIDF\"]]\n",
    "q_pos_ner = pd.DataFrame({\"Q_POS\": test_q_pos_ohv, \"Q_NER\": test_q_ner_ohv})\n",
    "q_emb_test = pd.concat([q_emb_test, q_pos_ner], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (Doc and Qn)\n",
    "\n",
    "The embeddings of the questions and answers of the train and test set can be found here:\n",
    "\n",
    "-   Train Document - doc_emb_train\n",
    "-   Train Q - q_emb_train\n",
    "-   Test Document - doc_emb_test\n",
    "-   Test Q - q_emb_test\n",
    "\n",
    "The max_document size is 1675 and max_question size is 23.\n",
    "\n",
    "### Converting into Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a min\n",
    "tf_final_doc_train = torch.tensor(final_doc_train, device=device)\n",
    "tf_final_doc_test = torch.tensor(final_doc_test, device=device)\n",
    "tf_final_qn_train = torch.tensor(final_qn_train, device=device)\n",
    "tf_final_qn_test = torch.tensor(final_qn_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "print(tf_final_doc_train.shape)\n",
    "print(tf_final_doc_test.shape)\n",
    "print(tf_final_qn_train.shape)\n",
    "print(tf_final_qn_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_final_doc_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_doc_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 in tf_final_doc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ans_labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_doc_ques[\"Document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_doc_ans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {\n",
    "    \"N\": 0,\n",
    "    \"S\": 1,\n",
    "    \"I\": 2,\n",
    "    \"E\": 3,\n",
    "}  # Define a mapping from labels to integers\n",
    "\n",
    "target = []\n",
    "for labels in train_doc_ans_labels:\n",
    "    encoded_labels = [label_to_int[label] for label in labels]\n",
    "    # encoded_tensor = torch.tensor(encoded_labels, device=device)\n",
    "    target.append(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_targets = []\n",
    "inner_targets = []\n",
    "end_targets = []\n",
    "none_targets = []\n",
    "\n",
    "# define the desired length\n",
    "desired_length = 1675\n",
    "\n",
    "\n",
    "for labels in train_doc_ans_labels:\n",
    "    start_target = [1 if label == \"S\" else 0 for label in labels]\n",
    "    inner_target = [1 if label == \"I\" else 0 for label in labels]\n",
    "    end_target = [1 if label == \"E\" else 0 for label in labels]\n",
    "    none_target = [1 if label == \"N\" else 0 for label in labels]\n",
    "\n",
    "    start_target = torch.tensor(start_target, device=device)\n",
    "    inner_target = torch.tensor(inner_target, device=device)\n",
    "    end_target = torch.tensor(end_target, device=device)\n",
    "    none_target = torch.tensor(none_target, device=device)\n",
    "\n",
    "    start_target_padding = desired_length - start_target.shape[0]\n",
    "    inner_target_padding = desired_length - inner_target.shape[0]\n",
    "    end_target_padding = desired_length - end_target.shape[0]\n",
    "    none_target_padding = desired_length - none_target.shape[0]\n",
    "\n",
    "    start_target = torch.nn.functional.pad(start_target, (0, start_target_padding))\n",
    "    inner_target = torch.nn.functional.pad(inner_target, (0, inner_target_padding))\n",
    "    end_target = torch.nn.functional.pad(end_target, (0, end_target_padding))\n",
    "    none_target = torch.nn.functional.pad(none_target, (0, none_target_padding))\n",
    "\n",
    "    start_targets.append(start_target)\n",
    "    inner_targets.append(inner_target)\n",
    "    end_targets.append(end_target)\n",
    "    none_targets.append(none_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_final_doc_train[0].long())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGuzHPE87Ya"
   },
   "source": [
    "# 3.Model Testing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZVeNYIH9IaL"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cTNGfO0h9I3W"
   },
   "source": [
    "### 3.1. Input Embedding Ablation Study\n",
    "\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEVsyvrc9VHL"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uX7nFwMo9WBE"
   },
   "source": [
    "### 3.2. Attention Ablation Study\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfRK-BeiNSVi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0VAR8GF9hSD"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "llzGjUe6NDnB"
   },
   "source": [
    "### 3.3. Hyper Parameter Testing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Xj4PNyrNDBH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
