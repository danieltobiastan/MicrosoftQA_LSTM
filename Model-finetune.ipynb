{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the data wrangling bit can be quite computationally intensive, and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (22.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (2.0.14)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: Mako in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load in the np data from the cleaneddata folder\n",
    "final_doc_test = np.load(\"cleaneddata/final_doc_test.npy\")\n",
    "final_doc_train = np.load(\"cleaneddata/final_doc_train.npy\")\n",
    "final_qn_train = np.load(\"cleaneddata/final_qn_train.npy\")\n",
    "final_qn_test = np.load(\"cleaneddata/final_qn_test.npy\")\n",
    "tr_labels = np.load(\"cleaneddata/tr_labels.npy\")\n",
    "ts_labels = np.load(\"cleaneddata/ts_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 200, 156) (2117, 200, 156) (2117, 23, 156) (630, 23, 156) (2117, 200) (630, 200)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of all the above\n",
    "print(\n",
    "    final_doc_test.shape,\n",
    "    final_doc_train.shape,\n",
    "    final_qn_train.shape,\n",
    "    final_qn_test.shape,\n",
    "    tr_labels.shape,\n",
    "    ts_labels.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy arrays to tensors\n",
    "final_doc_test = torch.from_numpy(final_doc_test).to(device=device, dtype=torch.float32)\n",
    "final_doc_train = torch.from_numpy(final_doc_train).to(\n",
    "    device=device, dtype=torch.float32\n",
    ")\n",
    "final_qn_train = torch.from_numpy(final_qn_train).to(device=device, dtype=torch.float32)\n",
    "final_qn_test = torch.from_numpy(final_qn_test).to(device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630, 200, 156]) torch.Size([2117, 200, 156]) torch.Size([2117, 23, 156]) torch.Size([630, 23, 156])\n"
     ]
    }
   ],
   "source": [
    "# check the shapes of the tensors\n",
    "print(\n",
    "    final_doc_test.shape,\n",
    "    final_doc_train.shape,\n",
    "    final_qn_train.shape,\n",
    "    final_qn_test.shape,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Embedding Ablation Study**\n",
    "\n",
    "In the model input embedding Ablation study, we are given 3 variations of input embeddings to test. We will test 3 options:\n",
    "\n",
    "1. Word2Vec only # 100 dims\n",
    "2. Word2Vec + Tf-IDF # 101 dims\n",
    "3. Word2Vec + all features (TF-IDF, POS, NER) # 156 dims\n",
    "\n",
    "Since we are using tensors, we can use tensor slicing to take out the relevant features.\n",
    "Our tensor of embeddings are built as follows (w2v, TF-IDF, POS, NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensors(tf_doc_train, tf_doc_test, tf_qn_train, tf_qn_test, option=3):\n",
    "    if option == 3:\n",
    "        return tf_doc_train, tf_doc_test, tf_qn_train, tf_qn_test\n",
    "    elif option == 1:\n",
    "        tf_doc_train = tf_doc_train[:, :, :100]\n",
    "        tf_doc_test = tf_doc_test[:, :, :100]\n",
    "        tf_qn_train = tf_qn_train[:, :, :100]\n",
    "        tf_qn_test = tf_qn_test[:, :, :100]\n",
    "        return tf_doc_train, tf_doc_test, tf_qn_train, tf_qn_test\n",
    "    elif option == 2:\n",
    "        tf_doc_train = tf_doc_train[:, :, :101]\n",
    "        tf_doc_test = tf_doc_test[:, :, :101]\n",
    "        tf_qn_train = tf_qn_train[:, :, :101]\n",
    "        tf_qn_test = tf_qn_test[:, :, :101]\n",
    "        return tf_doc_train, tf_doc_test, tf_qn_train, tf_qn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from label to index\n",
    "label2index = {\"N\": 0, \"S\": 1, \"I\": 2, \"E\": 3}\n",
    "\n",
    "# Find the maximum length of the label lists\n",
    "max_len = final_doc_train.shape[1]\n",
    "\n",
    "# Create a tensor to hold the one-hot encoded labels\n",
    "train_labels = torch.zeros(\n",
    "    len(tr_labels), max_len, len(label2index), device=device, dtype=torch.float32\n",
    ")\n",
    "test_labels = torch.zeros(\n",
    "    len(ts_labels),\n",
    "    max_len,\n",
    "    len(label2index),\n",
    "    device=device,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# Sets the first element of the third dimension of the target_labels tensor to 1\n",
    "train_labels[:, :, 0] = 1\n",
    "test_labels[:, :, 0] = 1\n",
    "\n",
    "# Iterate over the label lists and one-hot encode the labels\n",
    "for i, label_list in enumerate(tr_labels):\n",
    "    for j, label in enumerate(label_list):\n",
    "        index = label2index[label]\n",
    "        # Sets all elements of the target_labels tensor at position (i,j) to 0\n",
    "        train_labels[i, j] = 0\n",
    "        train_labels[i, j, index] = 1\n",
    "\n",
    "for i, label_list in enumerate(ts_labels):\n",
    "    for j, label in enumerate(label_list):\n",
    "        index = label2index[label]\n",
    "        # Sets all elements of the target_labels tensor at position (i,j) to 0\n",
    "        test_labels[i, j] = 0\n",
    "        test_labels[i, j, index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Reshape the target labels tensor\n",
    "reshaped_target_labels = (\n",
    "    train_labels.view(-1, 4).cpu().numpy()\n",
    ")  # Assuming it's on the GPU\n",
    "\n",
    "# Flatten the reshaped target labels\n",
    "flattened_target_labels = reshaped_target_labels.argmax(axis=1)\n",
    "\n",
    "# Calculate the class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=[0, 1, 2, 3], y=flattened_target_labels\n",
    ")\n",
    "\n",
    "# Convert the class weights to a PyTorch tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing complete at this stage, we should check again the shapes of the tensors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from enum import Enum\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of the model for the Document BiLSTM\n",
    "\n",
    "\n",
    "class DocumentBiRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_layers=1,\n",
    "    ):\n",
    "        super(DocumentBiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor):\n",
    "        input = input.unsqueeze(1)\n",
    "        output: Tensor\n",
    "        output, _ = self.lstm(input)\n",
    "        # print(\"document output shape: \", output.shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Architecture of the model for the Question BiLSTM\n",
    "\n",
    "\n",
    "class QuestionBiRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_layers=1,\n",
    "    ):\n",
    "        super(QuestionBiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor):\n",
    "        input = input.unsqueeze(1)\n",
    "        output, (hn, cn) = self.lstm(input)\n",
    "        forward_hn = hn[-2, :, :]\n",
    "        backward_hn = hn[-1, :, :]\n",
    "        hidden = torch.cat((forward_hn, backward_hn), dim=-1).unsqueeze(0)\n",
    "        # print(\"question hidden shape: \", hidden.shape)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "# attention methods\n",
    "class AttentionMethod(Enum):\n",
    "    DOT_PRODUCT = \"dot_product\"\n",
    "    SCALE_DOT_PRODUCT = \"scale_dot_product\"\n",
    "    COSINE_SIMILARITY = \"cosine_similarity\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "\n",
    "# Architecture of the model for the Attention Calculation\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ques_len,\n",
    "        hidden_size: int,\n",
    "        attention_method: Literal[\n",
    "            \"dot_product\",\n",
    "            \"scale_dot_product\",\n",
    "            \"cosine_similarity\",\n",
    "        ] = \"dot_product\",\n",
    "    ):\n",
    "        super(Attention, self).__init__()\n",
    "        self.out = nn.Linear(ques_len, hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_method = AttentionMethod(attention_method)\n",
    "\n",
    "    def forward(self, document_output, question_summary):\n",
    "        if self.attention_method == AttentionMethod.DOT_PRODUCT:\n",
    "            document_output = document_output.permute(\n",
    "                1, 0, 2\n",
    "            )  # torch.Size([200, 1, 16])\n",
    "            question_summary = question_summary.permute(\n",
    "                1, 2, 0\n",
    "            )  # torch.Size([1, 16, 1])\n",
    "\n",
    "            attention_scores = torch.bmm(document_output, question_summary).permute(\n",
    "                1, 0, 2\n",
    "            )\n",
    "            # get attention weights\n",
    "            attention_weights = nn.functional.softmax(attention_scores, dim=1)\n",
    "            # attention_scores = torch.bmm(document_output, question_summary) / np.sqrt(self.hidden_size)\n",
    "            # get context vector\n",
    "            context_scores = torch.bmm(\n",
    "                document_output.permute(1, 2, 0), attention_weights\n",
    "            ).permute(0, 2, 1)\n",
    "            return context_scores\n",
    "\n",
    "        elif self.attention_method == AttentionMethod.SCALE_DOT_PRODUCT:\n",
    "            document_output = document_output.permute(1, 0, 2)\n",
    "            question_summary = question_summary.permute(1, 2, 0)\n",
    "            attention_scores = torch.bmm(document_output, question_summary).permute(\n",
    "                1, 0, 2\n",
    "            ) / np.sqrt(self.hidden_size)\n",
    "            attention_weights = nn.functional.softmax(attention_scores, dim=1)\n",
    "            context_scores = torch.bmm(\n",
    "                document_output.permute(1, 2, 0), attention_weights\n",
    "            ).permute(0, 2, 1)\n",
    "            return context_scores\n",
    "\n",
    "        elif self.attention_method == AttentionMethod.COSINE_SIMILARITY:\n",
    "            document_output = document_output.permute(1, 0, 2)\n",
    "            question_summary = question_summary.permute(1, 2, 0)\n",
    "            question_summary = question_summary.squeeze(-1)\n",
    "            # cosine similarity attention:\n",
    "            cos_sim = F.cosine_similarity(\n",
    "                document_output, question_summary.unsqueeze(0), dim=-1\n",
    "            ).T.unsqueeze(1)\n",
    "            attention_weights = nn.functional.softmax(cos_sim, dim=1)\n",
    "            context_scores = torch.bmm(\n",
    "                document_output.permute(1, 2, 0), attention_weights\n",
    "            ).permute(0, 2, 1)\n",
    "            return context_scores\n",
    "\n",
    "\n",
    "# Architecture of the model for the Attention Weighted Document Representation a.k.a ReadingComprehension\n",
    "class ReadingComprehensionModel(nn.Module):\n",
    "    def __init__(self, document_rnn, question_rnn, attention, hidden_size, output_size):\n",
    "        super(ReadingComprehensionModel, self).__init__()\n",
    "        self.document_rnn = document_rnn\n",
    "        self.question_rnn = question_rnn\n",
    "        self.attention = attention\n",
    "        self.linear = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.linear2 = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def predict_label(self, attention_output):\n",
    "        attention_output = torch.squeeze(attention_output, 1)\n",
    "        # pass to linear\n",
    "        pred_weights = self.linear(attention_output)\n",
    "        pred_weights = self.linear2(pred_weights)\n",
    "        # get the softmax\n",
    "        # pred_weights = nn.functional.softmax(pred_weights, dim=1)\n",
    "        return pred_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "\n",
    "\n",
    "def trainIter(\n",
    "    model,\n",
    "    document_inputs,\n",
    "    question_inputs,\n",
    "    target_labels,\n",
    "    num_epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    verbose=True,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = 0\n",
    "        for document_input, question_input, target_label in zip(\n",
    "            document_inputs, question_inputs, target_labels\n",
    "        ):\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            document_output = model.document_rnn(document_input)\n",
    "            question_summary = model.question_rnn(question_input)\n",
    "\n",
    "            attention_output = model.attention(document_output, question_summary)\n",
    "\n",
    "            token_label_logits = model.predict_label(attention_output).to(device)\n",
    "\n",
    "            # print(\"token label logits shape: \", token_label_logits)\n",
    "            # print(\"target label shape: \", target_label.shape)\n",
    "            # print(\"token label logits: \", token_label_logits)\n",
    "\n",
    "            # print(token_label_logits[0])\n",
    "            # print(target_label[0])\n",
    "            # raise TypeError(\"stop\")\n",
    "\n",
    "            loss += criterion(token_label_logits, target_label)\n",
    "            optimizer.zero_grad()\n",
    "            # print(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = loss.item() / len(document_inputs)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalutation of the model\n",
    "\n",
    "START_LABEL = 1\n",
    "END_LABEL = 3\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model,\n",
    "    document_inputs,\n",
    "    question_inputs,\n",
    "    target_labels,\n",
    "    criterion,\n",
    "    output_dict=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        for document_input, question_input, target_label in zip(\n",
    "            document_inputs, question_inputs, target_labels\n",
    "        ):\n",
    "            document_output = model.document_rnn(document_input)\n",
    "            question_summary = model.question_rnn(question_input)\n",
    "            attention_output = model.attention(document_output, question_summary)\n",
    "            token_label_logits = model.predict_label(attention_output).to(device)\n",
    "            loss += criterion(token_label_logits, target_label)\n",
    "\n",
    "            # print(token_label_logits)\n",
    "\n",
    "            predictions = token_label_logits.argmax(dim=-1).cpu().numpy()\n",
    "            targets = target_label.argmax(dim=-1).cpu().numpy()\n",
    "            # print(predictions == 1)\n",
    "\n",
    "            if any(targets == START_LABEL) and any(targets == END_LABEL):\n",
    "                # Find indices of start and end tokens\n",
    "                start_token_idx = np.where(targets == START_LABEL)[0]\n",
    "                end_token_idx = np.where(targets == END_LABEL)[0]\n",
    "\n",
    "                # print(\"target: \", targets[start_token_idx[0] : end_token_idx[0] + 1])\n",
    "                # print(\n",
    "                #    \"prediction: \",\n",
    "                #    predictions[start_token_idx[0] : end_token_idx[0] + 1],\n",
    "                # )\n",
    "                # print()\n",
    "\n",
    "                # Take slice of predictions and target_labels for sentence tokens\n",
    "                sentence_prediction = predictions[\n",
    "                    start_token_idx[0] : end_token_idx[0] + 1\n",
    "                ]\n",
    "                sentence_target = targets[start_token_idx[0] : end_token_idx[0] + 1]\n",
    "\n",
    "                all_predictions.extend(sentence_prediction)\n",
    "                all_targets.extend(sentence_target)\n",
    "            else:\n",
    "                # Use the whole document since there is no answer\n",
    "                all_predictions.extend(predictions)\n",
    "                all_targets.extend(targets)\n",
    "\n",
    "        # print(all_predictions)\n",
    "        # print(all_targets)\n",
    "\n",
    "        avg_loss = loss.item() / len(document_inputs)\n",
    "        accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        precision = precision_score(all_targets, all_predictions, average=\"macro\")\n",
    "        recall = recall_score(all_targets, all_predictions, average=\"macro\")\n",
    "        f1 = f1_score(all_targets, all_predictions, average=\"macro\")\n",
    "        cr = classification_report(\n",
    "            all_targets, all_predictions, output_dict=output_dict\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\"\n",
    "            )\n",
    "\n",
    "        return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior to training\n",
    "as_doc_train, as_doc_test, as_qn_train, as_qn_test = convert_tensors(\n",
    "    final_doc_train, final_doc_test, final_qn_train, final_qn_test, 3\n",
    ")\n",
    "# if not running any ablation, use the free up space by deleting np arrays:\n",
    "# del final_doc_test, final_doc_train, final_qn_train, final_qn_test, tr_labels, ts_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of the training\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def train(\n",
    "    as_doc_train=as_doc_train,\n",
    "    as_qn_train=as_qn_train,\n",
    "    train_labels=train_labels,\n",
    "    hidden_size=64,\n",
    "    epochs=10,\n",
    "    learning_rate=0.01,\n",
    "    num_layers=1,\n",
    "    token_labels=4,\n",
    "    attention_method: Literal[\n",
    "        \"dot_product\",\n",
    "        \"scale_dot_product\",\n",
    "        \"cosine_similarity\",\n",
    "    ] = \"dot_product\",\n",
    "    verbose=True,\n",
    "):\n",
    "    # note the names of the tensors are changed to:\n",
    "    # as_doc_train, as_doc_test, as_qn_train, as_qn_test, train_labels, test_labels are called before in the ablation part\n",
    "    # to avoid confusion with the original tensors\n",
    "\n",
    "    # as_doc_train, as_doc_test, as_qn_train, as_qn_test\n",
    "\n",
    "    document_num_embeddings = as_doc_train.shape[2]\n",
    "    question_num_embeddings = as_qn_train.shape[2]\n",
    "    ques_len = as_qn_train.shape[1]\n",
    "\n",
    "    document_rnn = DocumentBiRNN(\n",
    "        hidden_size=hidden_size,\n",
    "        input_size=document_num_embeddings,\n",
    "        num_layers=num_layers,\n",
    "    ).to(device)\n",
    "    question_rnn = QuestionBiRNN(\n",
    "        input_size=question_num_embeddings,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "    ).to(device)\n",
    "    attention = Attention(ques_len, hidden_size, attention_method).to(device)\n",
    "    reading_comp = ReadingComprehensionModel(\n",
    "        document_rnn,\n",
    "        question_rnn,\n",
    "        attention,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=token_labels,\n",
    "    ).to(device)\n",
    "    reading_comp_optimizer = optim.AdamW(reading_comp.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        weight=class_weights\n",
    "    )  # to account for imbalanced class weights\n",
    "\n",
    "    trainIter(\n",
    "        reading_comp,\n",
    "        as_doc_train,\n",
    "        as_qn_train,\n",
    "        train_labels,\n",
    "        epochs,\n",
    "        criterion,\n",
    "        reading_comp_optimizer,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    return reading_comp, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6519, Accuracy: 0.3150, Precision: 0.2869, Recall: 0.7228, F1: 0.1774\n",
      "Loss: 0.7326, Accuracy: 0.2916, Precision: 0.2810, Recall: 0.6869, F1: 0.1615\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = \"./pytorch/dot_product_model.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    reading_comp_dot = torch.load(model_path)\n",
    "    criterion_dot = nn.CrossEntropyLoss(\n",
    "        weight=class_weights\n",
    "    )  # to account for imbalanced class weights\n",
    "else:\n",
    "    reading_comp_dot, criterion_dot = train(attention_method=\"dot_product\")\n",
    "    torch.save(reading_comp_dot, model_path)\n",
    "\n",
    "train_report, test_report = evaluate(\n",
    "    reading_comp_dot, as_doc_train, as_qn_train, train_labels, criterion_dot\n",
    "), evaluate(reading_comp_dot, as_doc_test, as_qn_test, test_labels, criterion_dot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Attention Ablation Study\n",
    "\n",
    "In this section, we study 3 different type of attention mechanisms between the question model and the document model. We ensured that the 3 attention mechanisms are ran on the same model hyperparameters, so as to keep things interpretable and standardized across the study.\n",
    "\n",
    "The hyperparameters of the training model are as follows:\n",
    "\n",
    "-   RNN (Bi-LSTM) Hidden Size: 64,\n",
    "-   Number of epochs: 10,\n",
    "-   Learning Rate: 0.01,\n",
    "-   Number of RNN (Bi-LSTM) layers: 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Ablation Study - Dot Product**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3877\n",
      "Epoch 2/10, Loss: 1.2985\n",
      "Epoch 3/10, Loss: 1.1640\n",
      "Epoch 4/10, Loss: 1.0213\n",
      "Epoch 5/10, Loss: 0.8929\n",
      "Epoch 6/10, Loss: 0.8886\n",
      "Epoch 7/10, Loss: 0.8762\n",
      "Epoch 8/10, Loss: 0.7103\n",
      "Epoch 9/10, Loss: 0.7208\n",
      "Epoch 10/10, Loss: 0.6745\n",
      "Loss: 0.6243, Accuracy: 0.4794, Precision: 0.2890, Recall: 0.7330, F1: 0.2368\n",
      "Loss: 0.7285, Accuracy: 0.4514, Precision: 0.2805, Recall: 0.6719, F1: 0.2169\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "reading_comp_dot, criterion_dot = train(attention_method=\"dot_product\")\n",
    "train_report, test_report = evaluate(\n",
    "    reading_comp_dot, as_doc_train, as_qn_train, train_labels, criterion_dot\n",
    "), evaluate(reading_comp_dot, as_doc_test, as_qn_test, test_labels, criterion_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.46      0.63    260691\n",
      "           1       0.03      0.90      0.05       826\n",
      "           2       0.12      0.67      0.21     19947\n",
      "           3       0.03      0.90      0.06       812\n",
      "\n",
      "    accuracy                           0.48    282276\n",
      "   macro avg       0.29      0.73      0.24    282276\n",
      "weighted avg       0.91      0.48      0.59    282276\n",
      "\n",
      "----------------------------------------------------------\n",
      "Evaluation on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.44      0.60     80177\n",
      "           1       0.02      0.85      0.05       230\n",
      "           2       0.10      0.65      0.17      5295\n",
      "           3       0.02      0.75      0.04       229\n",
      "\n",
      "    accuracy                           0.45     85931\n",
      "   macro avg       0.28      0.67      0.22     85931\n",
      "weighted avg       0.92      0.45      0.57     85931\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation for train and test set\n",
    "print(\"Evaluation on train set\")\n",
    "print(train_report)\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Evaluation on test set\")\n",
    "print(test_report)\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Ablation Study - Scaled Dot Product**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3930\n",
      "Epoch 2/10, Loss: 1.2962\n",
      "Epoch 3/10, Loss: 1.1624\n",
      "Epoch 4/10, Loss: 1.0126\n",
      "Epoch 5/10, Loss: 0.8761\n",
      "Epoch 6/10, Loss: 0.8303\n",
      "Epoch 7/10, Loss: 0.8849\n",
      "Epoch 8/10, Loss: 0.7509\n",
      "Epoch 9/10, Loss: 0.7617\n",
      "Epoch 10/10, Loss: 0.6999\n"
     ]
    }
   ],
   "source": [
    "# testing with scaled dot product attention\n",
    "reading_comp_scaled, criterion_scaled = train(attention_method=\"scale_dot_product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6344, Accuracy: 0.4300, Precision: 0.2885, Recall: 0.7360, F1: 0.2194\n",
      "Loss: 0.7066, Accuracy: 0.4040, Precision: 0.2813, Recall: 0.6986, F1: 0.2018\n",
      "Evaluation on train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.41      0.58    260691\n",
      "           1       0.03      0.93      0.05       826\n",
      "           2       0.13      0.66      0.21     19947\n",
      "           3       0.02      0.95      0.04       812\n",
      "\n",
      "    accuracy                           0.43    282276\n",
      "   macro avg       0.29      0.74      0.22    282276\n",
      "weighted avg       0.92      0.43      0.55    282276\n",
      "\n",
      "----------------------------------------------------------\n",
      "Evaluation on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.39      0.55     80177\n",
      "           1       0.02      0.89      0.04       230\n",
      "           2       0.10      0.64      0.18      5295\n",
      "           3       0.02      0.88      0.03       229\n",
      "\n",
      "    accuracy                           0.40     85931\n",
      "   macro avg       0.28      0.70      0.20     85931\n",
      "weighted avg       0.92      0.40      0.53     85931\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scaled_train_report, scaled_test_report = evaluate(\n",
    "    reading_comp_scaled, as_doc_train, as_qn_train, train_labels, criterion_scaled\n",
    "), evaluate(reading_comp_scaled, as_doc_test, as_qn_test, test_labels, criterion_scaled)\n",
    "\n",
    "# model evaluation for train and test set\n",
    "print(\"Evaluation on train set\")\n",
    "print(scaled_train_report)\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Evaluation on test set\")\n",
    "print(scaled_test_report)\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Ablation Study - Cosine Similarity**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3923\n",
      "Epoch 2/10, Loss: 1.2907\n",
      "Epoch 3/10, Loss: 1.1422\n",
      "Epoch 4/10, Loss: 0.9780\n",
      "Epoch 5/10, Loss: 0.8600\n",
      "Epoch 6/10, Loss: 0.9419\n",
      "Epoch 7/10, Loss: 0.8626\n",
      "Epoch 8/10, Loss: 0.8444\n",
      "Epoch 9/10, Loss: 0.7202\n",
      "Epoch 10/10, Loss: 0.7252\n"
     ]
    }
   ],
   "source": [
    "# testing with cosine similarity attention\n",
    "reading_comp_cosine, criterion_cosine = train(attention_method=\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7232, Accuracy: 0.3062, Precision: 0.2883, Recall: 0.7168, F1: 0.1751\n",
      "Loss: 0.8248, Accuracy: 0.2832, Precision: 0.2822, Recall: 0.6633, F1: 0.1586\n",
      "Evaluation on train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.26      0.42    260691\n",
      "           1       0.02      0.91      0.05       826\n",
      "           2       0.10      0.81      0.19     19947\n",
      "           3       0.03      0.89      0.05       812\n",
      "\n",
      "    accuracy                           0.31    282276\n",
      "   macro avg       0.29      0.72      0.18    282276\n",
      "weighted avg       0.93      0.31      0.40    282276\n",
      "\n",
      "----------------------------------------------------------\n",
      "Evaluation on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.39     80177\n",
      "           1       0.02      0.84      0.04       230\n",
      "           2       0.09      0.81      0.16      5295\n",
      "           3       0.02      0.76      0.04       229\n",
      "\n",
      "    accuracy                           0.28     85931\n",
      "   macro avg       0.28      0.66      0.16     85931\n",
      "weighted avg       0.94      0.28      0.38     85931\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for train and test set\n",
    "cosine_train_report, cosine_test_report = evaluate(\n",
    "    reading_comp_cosine, as_doc_train, as_qn_train, train_labels, criterion_cosine\n",
    "), evaluate(reading_comp_cosine, as_doc_test, as_qn_test, test_labels, criterion_cosine)\n",
    "\n",
    "print(\"Evaluation on train set\")\n",
    "print(cosine_train_report)\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Evaluation on test set\")\n",
    "print(cosine_test_report)\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Embeddings Ablation Study\n",
    "\n",
    "The above model used the full context vector with all word embeddings taken (Word2Vec, POS, NER, TF-IDF). In this section, we want to study the results of:\n",
    "\n",
    "1. Word2Vec Word embeddings only\n",
    "2. Word2Vec + TF-IDF\n",
    "3. Full vector, which we have ran the results above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeds only\n",
    "as_doc_train, as_doc_test, as_qn_train, as_qn_test = convert_tensors(\n",
    "    final_doc_train, final_doc_test, final_qn_train, final_qn_test, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation for train and test set\n",
    "print(\"Evaluation on train set\")\n",
    "print(train_report)\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Evaluation on test set\")\n",
    "print(test_report)\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Ablation Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-20 02:10:09,784]\u001b[0m A new study created in RDB with name: reading_comprehension\u001b[0m\n",
      "c:\\Users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f10e7bf4b374b2a9cc896273db4d2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0000, F1: 0.1789\n",
      "Learning rate: 0.0001, F1: 0.0726\n",
      "\u001b[32m[I 2023-05-20 02:18:45,065]\u001b[0m Trial 1 finished with value: 0.17893999001974925 and parameters: {'learning_rate': 1e-05}. Best is trial 1 with value: 0.17893999001974925.\u001b[0m\n",
      "\u001b[32m[I 2023-05-20 02:18:45,109]\u001b[0m Trial 0 finished with value: 0.0726473386810972 and parameters: {'learning_rate': 0.0001}. Best is trial 1 with value: 0.17893999001974925.\u001b[0m\n",
      "Learning rate: 0.1000, F1: 0.2102\n",
      "Learning rate: 0.0100, F1: 0.2531\n",
      "\u001b[32m[I 2023-05-20 02:28:15,891]\u001b[0m Trial 2 finished with value: 0.21015808025039706 and parameters: {'learning_rate': 0.1}. Best is trial 2 with value: 0.21015808025039706.\u001b[0m\n",
      "\u001b[32m[I 2023-05-20 02:28:15,900]\u001b[0m Trial 3 finished with value: 0.253149620219665 and parameters: {'learning_rate': 0.01}. Best is trial 3 with value: 0.253149620219665.\u001b[0m\n",
      "Learning rate: 0.0010, F1: 0.1692\n",
      "\u001b[32m[I 2023-05-20 02:33:19,426]\u001b[0m Trial 4 finished with value: 0.16921768934114767 and parameters: {'learning_rate': 0.001}. Best is trial 3 with value: 0.253149620219665.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to search over\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    # Create a KFold object for cross-validation\n",
    "    kf = KFold(n_splits=3)\n",
    "\n",
    "    # Initialize a list to store the cross-validation scores\n",
    "    cv_scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, val_index in kf.split(as_doc_train):\n",
    "        # Split the data into training and validation sets\n",
    "        doc_train, doc_val = as_doc_train[train_index], as_doc_train[val_index]\n",
    "        que_train, que_val = as_qn_train[train_index], as_qn_train[val_index]\n",
    "        label_train, label_val = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "        # Train the model on the training set\n",
    "        reading_comp_dot, criterion_dot = train(\n",
    "            doc_train,\n",
    "            que_train,\n",
    "            label_train,\n",
    "            attention_method=\"dot_product\",\n",
    "            learning_rate=learning_rate,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        val_report = evaluate(\n",
    "            reading_comp_dot,\n",
    "            doc_val,\n",
    "            que_val,\n",
    "            label_val,\n",
    "            criterion_dot,\n",
    "            output_dict=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "        # Store the validation score\n",
    "        cv_scores.append(val_report[\"macro avg\"][\"f1-score\"])\n",
    "    print(f\"Learning rate: {learning_rate:.4f}, F1: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "    # Return the average cross-validation score\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study_name = \"reading_comprehension\"  # Unique identifier of the study.\n",
    "storage_name = f\"sqlite:///./optuna/{study_name}.db\"\n",
    "sampler = optuna.samplers.GridSampler({\"learning_rate\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]})\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=5, n_jobs=2, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-dashboard\n",
      "  Downloading optuna_dashboard-0.9.2-py3-none-any.whl (4.4 MB)\n",
      "     ---------------------------------------- 4.4/4.4 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (22.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (1.2.2)\n",
      "Collecting bottle\n",
      "  Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.2/90.2 kB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: optuna>=2.4.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (3.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (1.23.5)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (2.0.14)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (1.11.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.4.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from colorlog->optuna>=2.4.0->optuna-dashboard) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.1)\n",
      "Installing collected packages: bottle, optuna-dashboard\n",
      "Successfully installed bottle-0.12.25 optuna-dashboard-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%optuna-dashboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# %pip install optuna-dashboard\n",
    "# %optuna-dashboard sqlite:///db.sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.253149620219665\n",
      "Best Params: \n",
      "  learning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna-dashboard in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (1.2.2)\n",
      "Requirement already satisfied: optuna>=2.4.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (3.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (22.0)\n",
      "Requirement already satisfied: bottle in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna-dashboard) (0.12.25)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (2.0.14)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from optuna>=2.4.0->optuna-dashboard) (4.65.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from colorlog->optuna>=2.4.0->optuna-dashboard) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\nicho\\.pyenv\\pyenv-win\\versions\\miniconda3-py310_23.1.0-1\\envs\\nlp\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%optuna-dashboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# %pip install plotly\n",
    "# %pip install optuna-dashboard\n",
    "# %optuna-dashboard sqlite:///./optuna/reading_comprehension.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number     value             datetime_start          datetime_complete  \\\n",
      "0       0  0.072647 2023-05-20 02:10:09.848122 2023-05-20 02:18:45.060281   \n",
      "1       1  0.178940 2023-05-20 02:10:09.864671 2023-05-20 02:18:45.028565   \n",
      "2       2  0.210158 2023-05-20 02:18:45.119037 2023-05-20 02:28:15.830017   \n",
      "3       3  0.253150 2023-05-20 02:18:45.209923 2023-05-20 02:28:15.856555   \n",
      "4       4  0.169218 2023-05-20 02:28:15.935802 2023-05-20 02:33:19.404487   \n",
      "\n",
      "                duration  params_learning_rate  system_attrs_grid_id  \\\n",
      "0 0 days 00:08:35.212159               0.00010                     1   \n",
      "1 0 days 00:08:35.163894               0.00001                     0   \n",
      "2 0 days 00:09:30.710980               0.10000                     4   \n",
      "3 0 days 00:09:30.646632               0.01000                     3   \n",
      "4 0 days 00:05:03.468685               0.00100                     2   \n",
      "\n",
      "                           system_attrs_search_space     state  \n",
      "0  {'learning_rate': [1e-05, 0.0001, 0.001, 0.01,...  COMPLETE  \n",
      "1  {'learning_rate': [1e-05, 0.0001, 0.001, 0.01,...  COMPLETE  \n",
      "2  {'learning_rate': [1e-05, 0.0001, 0.001, 0.01,...  COMPLETE  \n",
      "3  {'learning_rate': [1e-05, 0.0001, 0.001, 0.01,...  COMPLETE  \n",
      "4  {'learning_rate': [1e-05, 0.0001, 0.001, 0.01,...  COMPLETE  \n"
     ]
    }
   ],
   "source": [
    "# Get a DataFrame containing the results of all trials\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4
         ],
         "y": [
          0.0726473386810972,
          0.17893999001974925,
          0.21015808025039706,
          0.253149620219665,
          0.16921768934114767
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4
         ],
         "y": [
          0.0726473386810972,
          0.17893999001974925,
          0.21015808025039706,
          0.253149620219665,
          0.253149620219665
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          }
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.0001,
          0.00001,
          0.1,
          0.01,
          0.001
         ],
         "y": [
          0.0726473386810972,
          0.17893999001974925,
          0.21015808025039706,
          0.253149620219665,
          0.16921768934114767
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "xaxis": {
         "title": {
          "text": "learning_rate"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "reading_comprehension",
         "type": "scatter",
         "x": [
          0.0726473386810972,
          0.07447059405017364,
          0.07629384941925008,
          0.07811710478832652,
          0.07994036015740297,
          0.08176361552647941,
          0.08358687089555586,
          0.08541012626463229,
          0.08723338163370874,
          0.08905663700278518,
          0.09087989237186161,
          0.09270314774093806,
          0.0945264031100145,
          0.09634965847909095,
          0.0981729138481674,
          0.09999616921724383,
          0.10181942458632028,
          0.10364267995539672,
          0.10546593532447315,
          0.1072891906935496,
          0.10911244606262605,
          0.11093570143170249,
          0.11275895680077894,
          0.11458221216985537,
          0.11640546753893181,
          0.11822872290800826,
          0.12005197827708469,
          0.12187523364616114,
          0.12369848901523758,
          0.12552174438431402,
          0.12734499975339048,
          0.1291682551224669,
          0.13099151049154334,
          0.1328147658606198,
          0.13463802122969623,
          0.13646127659877266,
          0.13828453196784912,
          0.14010778733692558,
          0.141931042706002,
          0.14375429807507845,
          0.1455775534441549,
          0.14740080881323134,
          0.14922406418230777,
          0.15104731955138423,
          0.15287057492046066,
          0.1546938302895371,
          0.15651708565861355,
          0.15834034102768998,
          0.16016359639676642,
          0.16198685176584288,
          0.16381010713491934,
          0.16563336250399574,
          0.1674566178730722,
          0.16927987324214866,
          0.17110312861122506,
          0.17292638398030152,
          0.17474963934937798,
          0.17657289471845442,
          0.17839615008753085,
          0.1802194054566073,
          0.18204266082568374,
          0.18386591619476017,
          0.18568917156383663,
          0.18751242693291306,
          0.1893356823019895,
          0.19115893767106595,
          0.1929821930401424,
          0.19480544840921882,
          0.19662870377829528,
          0.19845195914737174,
          0.20027521451644814,
          0.2020984698855246,
          0.20392172525460106,
          0.20574498062367746,
          0.20756823599275392,
          0.20939149136183038,
          0.2112147467309068,
          0.21303800209998325,
          0.2148612574690597,
          0.21668451283813617,
          0.21850776820721257,
          0.22033102357628903,
          0.2221542789453655,
          0.2239775343144419,
          0.22580078968351835,
          0.22762404505259481,
          0.22944730042167122,
          0.23127055579074768,
          0.23309381115982414,
          0.23491706652890054,
          0.236740321897977,
          0.23856357726705346,
          0.24038683263612987,
          0.24221008800520633,
          0.24403334337428279,
          0.24585659874335924,
          0.24767985411243565,
          0.2495031094815121,
          0.25132636485058857,
          0.253149620219665
         ],
         "y": [
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Empirical Distribution Function Plot"
        },
        "xaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Cumulative Probability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_edf(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
