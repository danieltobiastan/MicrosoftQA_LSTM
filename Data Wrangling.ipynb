{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "train_data = pd.read_csv(\"WikiQA-train.tsv\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"WikiQA-test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the unique questions from the train and test data frames, including the documentID and the DocumentTitle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_documenttag(data):\n",
    "    qd = data[\n",
    "        [\"Question\", \"QuestionID\", \"DocumentID\", \"DocumentTitle\"]\n",
    "    ].drop_duplicates()\n",
    "    return qd\n",
    "\n",
    "\n",
    "train_question_doctag = get_questions_documenttag(train_data)\n",
    "test_question_doctag = get_questions_documenttag(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique questions\n",
    "train_questions = train_question_doctag[\"Question\"]\n",
    "test_questions = test_question_doctag[\"Question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique document ids\n",
    "train_docid = train_question_doctag[\"DocumentID\"]\n",
    "test_docid = test_question_doctag[\"DocumentID\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the answers to those questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(data, questions, documentids):\n",
    "    answers = []  # list of answers\n",
    "    for q in range(len(questions)):\n",
    "        question = questions.iloc[q]\n",
    "        doc_id = documentids.iloc[q]  # add the document id\n",
    "        df = data[data[\"Question\"] == question]\n",
    "        index = df.loc[df[\"Label\"] == 1][\"Sentence\"].index.values\n",
    "        if len(index) == 0:  # if no answer found\n",
    "            answers.append([question, doc_id, \"No answer\"])\n",
    "        else:  # if 1 answer found\n",
    "            answers.append([question, doc_id, df.loc[index[0], \"Sentence\"]])\n",
    "    return answers\n",
    "\n",
    "\n",
    "train_answers = pd.DataFrame(get_answers(train_data, train_questions, train_docid))\n",
    "test_answers = pd.DataFrame(get_answers(test_data, test_questions, test_docid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above get_answers returns train_answers and test_answers which, gives us in the following columns\n",
    "\n",
    "-   Question\n",
    "-   Related Document ID\n",
    "-   Answer (if no answer to that question, return no answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(data, questions, documentids):  # (done by Finn, tweaked by Dan)\n",
    "    documents = []\n",
    "    for q in range(len(questions)):\n",
    "        question = questions.iloc[q]\n",
    "        doc_id = documentids.iloc[q]  # add the document id\n",
    "        df = data[data[\"Question\"] == question]\n",
    "        sentences = df[\"Sentence\"].tolist()\n",
    "        for i in range(0, len(sentences) - 1):\n",
    "            sentences[i] = sentences[i] + \" \"\n",
    "        documents.append([doc_id, \"\".join(sentences)])\n",
    "    return documents\n",
    "\n",
    "\n",
    "train_documents = pd.DataFrame(\n",
    "    get_documents(train_data, train_questions, train_docid)\n",
    ")  # return the individual document in list\n",
    "test_documents = pd.DataFrame(\n",
    "    get_documents(test_data, test_questions, test_docid)\n",
    ")  # return the individual document in list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above train_documents and test_documents called from the get_documents gives us in the following columns\n",
    "\n",
    "-   Document ID\n",
    "-   Full Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming all the columns for more standardised access\n",
    "train_answers.columns = [\"Question\", \"DocumentID\", \"Answer\"]\n",
    "test_answers.columns = [\"Question\", \"DocumentID\", \"Answer\"]\n",
    "train_documents.columns = [\"DocumentID\", \"Document\"]\n",
    "test_documents.columns = [\"DocumentID\", \"Document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2117, 2117, 630, 630)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# result is 2117, 2117, 630, 630\n",
    "\n",
    "len(train_answers), len(train_documents), len(test_answers), len(test_documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior to tagging, we should maybe clean the document and answers first:** (stopped here)\n",
    "\n",
    "Maybe?\n",
    "\n",
    "-   lowercase (might lose context, but we can use on questions)\n",
    "-   removing any punctuation or weird symbols (do)\n",
    "-   removal of stop words? (probably not)\n",
    "\n",
    "Make sure that the pre-processing is standardised to be the same throughout doc and ans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just common English contractions. We used it in Lab 5 before!\n",
    "contraction_dict = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"this's\": \"this is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lower(text):\n",
    "    # Lowercase the text for question, answer and documents\n",
    "    text = text.lower()\n",
    "    for word, new_word in contraction_dict.items():\n",
    "        text = text.replace(word, new_word)  # dealing with contractions\n",
    "    pattern = r\"[^a-zA-Z0-9\\s]\"\n",
    "    cleaned_text = re.sub(pattern, \" \", text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "train_answers[[\"Question\", \"Answer\"]] = train_answers[[\"Question\", \"Answer\"]].applymap(\n",
    "    preprocess_lower\n",
    ")\n",
    "train_documents[\"Document\"] = train_documents[\"Document\"].apply(preprocess_lower)\n",
    "test_answers[[\"Question\", \"Answer\"]] = test_answers[[\"Question\", \"Answer\"]].applymap(\n",
    "    preprocess_lower\n",
    ")\n",
    "test_documents[\"Document\"] = test_documents[\"Document\"].apply(preprocess_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>a partly submerged glacier cave on perito more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>in physics   circular motion is a movement of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D5</td>\n",
       "      <td>apollo creed is a fictional character from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D6</td>\n",
       "      <td>in the united states  the title of federal jud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D7</td>\n",
       "      <td>the beretta 21a bobcat is a small pocket sized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>D2805</td>\n",
       "      <td>blue mountain state is an american comedy seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>D2806</td>\n",
       "      <td>apple inc   formerly apple computer  inc   is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>D2807</td>\n",
       "      <td>section 8 housing in the south bronx section 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>D2808</td>\n",
       "      <td>restaurants categorized by type and informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>D2810</td>\n",
       "      <td>u s  federal reserve notes in the mid 1990s th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DocumentID                                           Document\n",
       "0            D1  a partly submerged glacier cave on perito more...\n",
       "1            D2  in physics   circular motion is a movement of ...\n",
       "2            D5  apollo creed is a fictional character from the...\n",
       "3            D6  in the united states  the title of federal jud...\n",
       "4            D7  the beretta 21a bobcat is a small pocket sized...\n",
       "...         ...                                                ...\n",
       "2112      D2805  blue mountain state is an american comedy seri...\n",
       "2113      D2806  apple inc   formerly apple computer  inc   is ...\n",
       "2114      D2807  section 8 housing in the south bronx section 8...\n",
       "2115      D2808  restaurants categorized by type and informatio...\n",
       "2116      D2810  u s  federal reserve notes in the mid 1990s th...\n",
       "\n",
       "[2117 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(documents, answers):\n",
    "    tagged_documents = []\n",
    "    for q in range(len(answers)):\n",
    "        tagged_document = []\n",
    "        qn = answers[\"Question\"].loc[q]\n",
    "        doc_id = answers[\"DocumentID\"].loc[q]\n",
    "        content = documents.loc[documents[\"DocumentID\"] == doc_id, \"Document\"].values[0]\n",
    "        answer = answers[\"Answer\"].loc[q]\n",
    "\n",
    "        if answer == \"no answer\":\n",
    "            tokens = word_tokenize(content)\n",
    "            for j in range(len(tokens)):\n",
    "                tagged_document.append(\"N\")  # none\n",
    "        else:\n",
    "            parts = content.partition(answer)\n",
    "            for j in range(len(parts)):\n",
    "                tokens = word_tokenize(parts[j])\n",
    "                if j == 1:\n",
    "                    tagged_document.append(\"S\")  # start of answer\n",
    "                    for k in range(len(tokens) - 2):\n",
    "                        tagged_document.append(\"I\")  # inside of answer\n",
    "                    tagged_document.append(\"E\")  # end of answer\n",
    "                else:\n",
    "                    for k in range(len(tokens)):\n",
    "                        tagged_document.append(\"N\")  # outside answer\n",
    "        tagged_documents.append(tagged_document)\n",
    "    return tagged_documents\n",
    "\n",
    "\n",
    "train_doc_ans_labels = labelling(train_documents, train_answers)\n",
    "test_doc_ans_labels = labelling(test_documents, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'egg']\n",
      "['N', 'roll']\n",
      "['N', 'is']\n",
      "['N', 'a']\n",
      "['N', 'term']\n",
      "['N', 'used']\n",
      "['N', 'for']\n",
      "['N', 'many']\n",
      "['N', 'different']\n",
      "['N', 'foods']\n",
      "['N', 'around']\n",
      "['N', 'the']\n",
      "['N', 'world']\n",
      "['S', '2']\n",
      "['I', 'egg']\n",
      "['I', 'roll']\n",
      "['I', 'varieties']\n",
      "['I', 'of']\n",
      "['I', 'egg']\n",
      "['I', 'rolls']\n",
      "['I', 'are']\n",
      "['I', 'found']\n",
      "['I', 'in']\n",
      "['I', 'mainland']\n",
      "['I', 'china']\n",
      "['I', 'many']\n",
      "['I', 'chinese']\n",
      "['I', 'speaking']\n",
      "['I', 'regions']\n",
      "['I', 'of']\n",
      "['I', 'asia']\n",
      "['I', 'and']\n",
      "['I', 'chinese']\n",
      "['I', 'immigrant']\n",
      "['I', 'communities']\n",
      "['I', 'around']\n",
      "['I', 'the']\n",
      "['E', 'world']\n",
      "['N', 'egg']\n",
      "['N', 'rolls']\n",
      "['N', 'as']\n",
      "['N', 'referred']\n",
      "['N', 'to']\n",
      "['N', 'in']\n",
      "['N', 'china']\n",
      "['N', 'in']\n",
      "['N', 'guangdong']\n",
      "['N', 'and']\n",
      "['N', 'hong']\n",
      "['N', 'kong']\n",
      "['N', 'egg']\n",
      "['N', 'roll']\n",
      "['N', 'usually']\n",
      "['N', 'refers']\n",
      "['N', 'to']\n",
      "['N', 'biscuit']\n",
      "['N', 'roll']\n",
      "['N', 'this']\n",
      "['N', 'is']\n",
      "['N', 'a']\n",
      "['N', 'type']\n",
      "['N', 'of']\n",
      "['N', 'biscuit']\n",
      "['N', 'the']\n",
      "['N', 'ingredient']\n",
      "['N', 'included']\n",
      "['N', 'egg']\n",
      "['N', 'flour']\n",
      "['N', 'and']\n",
      "['N', 'sugar']\n",
      "['N', 'egg']\n",
      "['N', 'roll']\n",
      "['N', 'also']\n",
      "['N', 'is']\n",
      "['N', 'a']\n",
      "['N', 'dish']\n",
      "['N', 'in']\n",
      "['N', 'canton']\n",
      "['N', 'and']\n",
      "['N', 'hong']\n",
      "['N', 'kong']\n",
      "['N', 'this']\n",
      "['N', 'is']\n",
      "['N', 'usually']\n",
      "['N', 'made']\n",
      "['N', 'with']\n",
      "['N', 'vegetable']\n",
      "['N', 'within']\n",
      "['N', 'china']\n",
      "['N', 'egg']\n",
      "['N', 'rolls']\n",
      "['N', 'are']\n",
      "['N', 'eaten']\n",
      "['N', 'predominantly']\n",
      "['N', 'in']\n",
      "['N', 'the']\n",
      "['N', 'southeast']\n",
      "['N', 'and']\n",
      "['N', 'are']\n",
      "['N', 'not']\n",
      "['N', 'as']\n",
      "['N', 'commonly']\n",
      "['N', 'consumed']\n",
      "['N', 'in']\n",
      "['N', 'the']\n",
      "['N', 'north']\n",
      "['N', 'and']\n",
      "['N', 'western']\n",
      "['N', 'parts']\n",
      "['N', 'of']\n",
      "['N', 'china']\n",
      "['N', 'in']\n",
      "['N', 'american']\n",
      "['N', 'chinese']\n",
      "['N', 'cuisine']\n",
      "['N', 'an']\n",
      "['N', 'egg']\n",
      "['N', 'roll']\n",
      "['N', 'is']\n",
      "['N', 'a']\n",
      "['N', 'savory']\n",
      "['N', 'dish']\n",
      "['N', 'typically']\n",
      "['N', 'served']\n",
      "['N', 'as']\n",
      "['N', 'an']\n",
      "['N', 'appetizer']\n",
      "['N', 'it']\n",
      "['N', 'is']\n",
      "['N', 'usually']\n",
      "['N', 'stuffed']\n",
      "['N', 'with']\n",
      "['N', 'chicken']\n",
      "['N', 'pork']\n",
      "['N', 'or']\n",
      "['N', 'shrimp']\n",
      "['N', 'cabbage']\n",
      "['N', 'carrots']\n",
      "['N', 'tomatoes']\n",
      "['N', 'bean']\n",
      "['N', 'sprouts']\n",
      "['N', 'and']\n",
      "['N', 'other']\n",
      "['N', 'vegetables']\n",
      "['N', 'and']\n",
      "['N', 'then']\n",
      "['N', 'deep']\n",
      "['N', 'fried']\n",
      "['N', 'this']\n",
      "['N', 'variety']\n",
      "['N', 'of']\n",
      "['N', 'the']\n",
      "['N', 'egg']\n",
      "['N', 'roll']\n",
      "['N', 'is']\n",
      "['N', 'very']\n",
      "['N', 'common']\n",
      "['N', 'and']\n",
      "['N', 'popular']\n",
      "['N', 'across']\n",
      "['N', 'even']\n",
      "['N', 'regional']\n",
      "['N', 'varieties']\n",
      "['N', 'of']\n",
      "['N', 'american']\n",
      "['N', 'chinese']\n",
      "['N', 'food']\n",
      "['N', 'and']\n",
      "['N', 'is']\n",
      "['N', 'often']\n",
      "['N', 'included']\n",
      "['N', 'as']\n",
      "['N', 'part']\n",
      "['N', 'of']\n",
      "['N', 'a']\n",
      "['N', 'combination']\n",
      "['N', 'platter']\n",
      "['N', 'in']\n",
      "['N', 'montreal']\n",
      "['N', 'canada']\n",
      "['N', 'open']\n",
      "['N', 'ended']\n",
      "['N', 'eggrolls']\n",
      "['N', 'are']\n",
      "['N', 'a']\n",
      "['N', 'jewish']\n",
      "['N', 'chinese']\n",
      "['N', 'fusion']\n",
      "['N', 'dish']\n",
      "['N', 'they']\n",
      "['N', 'can']\n",
      "['N', 'be']\n",
      "['N', 'either']\n",
      "['N', 'kosher']\n",
      "['N', 'certified']\n",
      "['N', 'or']\n",
      "['N', 'merely']\n",
      "['N', 'kosher']\n",
      "['N', 'style']\n",
      "2  egg roll    varieties of egg rolls are found in mainland china   many chinese speaking regions of asia  and chinese immigrant communities around the world \n"
     ]
    }
   ],
   "source": [
    "# check if tags are good\n",
    "def testing_tokens(ind, labels, documents, answers):\n",
    "    for i, j in zip(labels[ind], word_tokenize(documents[\"Document\"][ind])):\n",
    "        print([i, j])\n",
    "    print(answers[\"Answer\"][ind])\n",
    "\n",
    "\n",
    "testing_tokens(1000, train_doc_ans_labels, train_documents, train_answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned Documents: train and test\n",
    "\n",
    "train_answers - contains the ['Question','DocumentID','Answer']\n",
    "\n",
    "train_documents - contains the ['DocumentID','Document']\n",
    "\n",
    "train_doc_ans_labels - contains a list of list of answer tags for each document,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare the document for word embeddings:\n",
    "train_doc_ques = pd.DataFrame(\n",
    "    {\"Document\": train_documents[\"Document\"], \"Question\": train_answers[\"Question\"]}\n",
    ")\n",
    "test_doc_ques = pd.DataFrame(\n",
    "    {\"Document\": test_documents[\"Document\"], \"Question\": test_answers[\"Question\"]}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "To use the CBOW model, we need the data in sentences. Extract this from the original dataset, don't use sent_tokenise, will mess with some of the fullstops, we want to maintain structure from above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokens(data):\n",
    "    sentence_list = []\n",
    "    for i in range(len(data)):\n",
    "        sentence_list.append(word_tokenize(data[i]))\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "train_doc_list = word_tokens(train_doc_ques[\"Document\"])\n",
    "train_ques_list = word_tokens(train_doc_ques[\"Question\"])\n",
    "test_doc_list = word_tokens(test_doc_ques[\"Document\"])\n",
    "test_ques_list = word_tokens(test_doc_ques[\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = train_doc_list + train_ques_list + test_doc_list + test_ques_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trained, don't have to run this multiple times\n",
    "wc_cbow_model = Word2Vec(\n",
    "    sentences=combined_text,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=2,\n",
    "    epochs=30,\n",
    ")\n",
    "# wc_cbow_model.save(\"cbow.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement QA\n",
    "\n",
    "1. Word Embeddings, using CBOW\n",
    "2. Feature Extraction 1 - POS tags\n",
    "3. Feature Extraction 2 - TF-IDF\n",
    "4. Feature Extraction 3 - NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if model in directory\n",
    "wc_cbow_model = Word2Vec.load(\"./cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(doc):\n",
    "    tokenized_doc = word_tokenize(doc)\n",
    "    embeddings = [wc_cbow_model.wv[word] for word in tokenized_doc]\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "train_doc_ques[\"Doc_Embeddings\"] = train_doc_ques[\"Document\"].apply(get_word_embeddings)\n",
    "train_doc_ques[\"Q_Embeddings\"] = train_doc_ques[\"Question\"].apply(get_word_embeddings)\n",
    "test_doc_ques[\"Doc_Embeddings\"] = test_doc_ques[\"Document\"].apply(get_word_embeddings)\n",
    "test_doc_ques[\"Q_Embeddings\"] = test_doc_ques[\"Question\"].apply(get_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ques[\"Doc_Tokens\"] = train_doc_ques[\"Document\"].apply(word_tokenize)\n",
    "train_doc_ques[\"Q_Tokens\"] = train_doc_ques[\"Question\"].apply(word_tokenize)\n",
    "test_doc_ques[\"Doc_Tokens\"] = test_doc_ques[\"Document\"].apply(word_tokenize)\n",
    "test_doc_ques[\"Q_Tokens\"] = test_doc_ques[\"Question\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max Seq Length is 924, Median is 182.0, Number of lines is 2117)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_max_length(column):\n",
    "    max_length = 0\n",
    "    lns = []\n",
    "    for i in range(len(column)):\n",
    "        lns.append(len(column[i]))\n",
    "        if len(column[i]) > max_length:\n",
    "            max_length = len(column[i])\n",
    "    return \"Max Seq Length is {}, Median is {}, Number of lines is {})\".format(\n",
    "        max_length, np.median(lns), len(lns)\n",
    "    )\n",
    "\n",
    "\n",
    "find_max_length(test_doc_ques[\"Doc_Embeddings\"])\n",
    "find_max_length(train_doc_ques[\"Doc_Embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_count(doc):\n",
    "    count = 0\n",
    "    for i in range(len(doc)):\n",
    "        if len(doc[\"Doc_Embeddings\"][i]) != len(doc[\"Doc_Tokens\"][i]):\n",
    "            count += 1\n",
    "        elif len(doc[\"Q_Embeddings\"][i]) != len(doc[\"Q_Tokens\"][i]):\n",
    "            count += 1\n",
    "        else:\n",
    "            continue\n",
    "    return count\n",
    "\n",
    "\n",
    "check_count(train_doc_ques)  # looks good"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, need to convert the POS tags, NER tags into embeddings. After this, pad the questions and answers to the max question/document length in the combined training and test set.\n",
    "\n",
    "### PoS Tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/daniel/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Apply the pos tags to the tokens\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# download the dependency and resource as required\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "train_doc_ques[\"Doc_POS\"] = train_doc_ques[\"Doc_Tokens\"].apply(pos_tag)\n",
    "train_doc_ques[\"Q_POS\"] = train_doc_ques[\"Q_Tokens\"].apply(pos_tag)\n",
    "test_doc_ques[\"Doc_POS\"] = test_doc_ques[\"Doc_Tokens\"].apply(pos_tag)\n",
    "test_doc_ques[\"Q_POS\"] = test_doc_ques[\"Q_Tokens\"].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'WRB'),\n",
       " ('many', 'JJ'),\n",
       " ('schools', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('ten', 'NN')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the POS tags: # looks ok\n",
    "train_doc_ques[\"Q_POS\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': 0,\n",
       " 'CC': 1,\n",
       " 'CD': 2,\n",
       " 'DT': 3,\n",
       " 'EX': 4,\n",
       " 'FW': 5,\n",
       " 'IN': 6,\n",
       " 'JJ': 7,\n",
       " 'JJR': 8,\n",
       " 'JJS': 9,\n",
       " 'MD': 10,\n",
       " 'NN': 11,\n",
       " 'NNP': 12,\n",
       " 'NNPS': 13,\n",
       " 'NNS': 14,\n",
       " 'PDT': 15,\n",
       " 'POS': 16,\n",
       " 'PRP': 17,\n",
       " 'PRP$': 18,\n",
       " 'RB': 19,\n",
       " 'RBR': 20,\n",
       " 'RBS': 21,\n",
       " 'RP': 22,\n",
       " 'SYM': 23,\n",
       " 'TO': 24,\n",
       " 'UH': 25,\n",
       " 'VB': 26,\n",
       " 'VBD': 27,\n",
       " 'VBG': 28,\n",
       " 'VBN': 29,\n",
       " 'VBP': 30,\n",
       " 'VBZ': 31,\n",
       " 'WDT': 32,\n",
       " 'WP': 33,\n",
       " 'WP$': 34,\n",
       " 'WRB': 35}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract all unique POS Tags\n",
    "all_pos_tags = (\n",
    "    train_doc_ques[\"Doc_POS\"].tolist()\n",
    "    + test_doc_ques[\"Doc_POS\"].tolist()\n",
    "    + train_doc_ques[\"Q_POS\"].tolist()\n",
    "    + test_doc_ques[\"Q_POS\"].tolist()\n",
    ")\n",
    "\n",
    "\n",
    "def get_unique_pos(data):\n",
    "    pos_tags = set()\n",
    "    for item in data:\n",
    "        for _, pos_tag in item:\n",
    "            pos_tags.add(pos_tag)\n",
    "\n",
    "    pos_tag_index = {tag: i for i, tag in enumerate(sorted(pos_tags))}\n",
    "    return pos_tag_index\n",
    "\n",
    "\n",
    "pos_iden = get_unique_pos(all_pos_tags)  # list of tags\n",
    "pos_iden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagging\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to run this:\n",
    "\n",
    "-   pip install spacy\n",
    "-   python -m spacy download en_core_web_sm\n",
    "\n",
    "If loaded for the first time, restart kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:24:54.108226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# nltk using Spacy\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# loading pre-trained model of NER\n",
    "#nlp = en_core_web_sm.load()\n",
    "#nlp.to_disk(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"./en_core_web_sm/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tagging(texts):\n",
    "    tagged_texts = []\n",
    "    for text in texts:\n",
    "        doc = spacy.tokens.Doc(nlp.vocab, words=text)\n",
    "        nlp.get_pipe(\"ner\")(doc)\n",
    "        tagged_texts.append([(token.text, token.ent_type_) for token in doc])\n",
    "    return tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take a while...\n",
    "train_doc_ques[\"Doc_NER\"] = ner_tagging(train_doc_ques[\"Doc_Tokens\"])\n",
    "train_doc_ques[\"Q_NER\"] = ner_tagging(train_doc_ques[\"Q_Tokens\"])\n",
    "test_doc_ques[\"Doc_NER\"] = ner_tagging(test_doc_ques[\"Doc_Tokens\"])\n",
    "test_doc_ques[\"Q_NER\"] = ner_tagging(test_doc_ques[\"Q_Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', ''),\n",
       " ('much', ''),\n",
       " ('are', ''),\n",
       " ('the', ''),\n",
       " ('harry', 'WORK_OF_ART'),\n",
       " ('potter', 'WORK_OF_ART'),\n",
       " ('movies', 'WORK_OF_ART'),\n",
       " ('worth', 'WORK_OF_ART')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_doc_ques[\"Q_NER\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'CARDINAL': 1,\n",
       " 'DATE': 2,\n",
       " 'EVENT': 3,\n",
       " 'FAC': 4,\n",
       " 'GPE': 5,\n",
       " 'LANGUAGE': 6,\n",
       " 'LAW': 7,\n",
       " 'LOC': 8,\n",
       " 'MONEY': 9,\n",
       " 'NORP': 10,\n",
       " 'ORDINAL': 11,\n",
       " 'ORG': 12,\n",
       " 'PERCENT': 13,\n",
       " 'PERSON': 14,\n",
       " 'PRODUCT': 15,\n",
       " 'QUANTITY': 16,\n",
       " 'TIME': 17,\n",
       " 'WORK_OF_ART': 18}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Similar approach to the POS\n",
    "\n",
    "# Extract all unique POS Tags\n",
    "all_ner_tags = (\n",
    "    train_doc_ques[\"Doc_NER\"].tolist()\n",
    "    + test_doc_ques[\"Doc_NER\"].tolist()\n",
    "    + train_doc_ques[\"Q_NER\"].tolist()\n",
    "    + test_doc_ques[\"Q_NER\"].tolist()\n",
    ")\n",
    "\n",
    "\n",
    "def get_unique_ner(data):\n",
    "    ner_tags = set()\n",
    "    for item in data:\n",
    "        for _, ner_tag in item:\n",
    "            ner_tags.add(ner_tag)\n",
    "\n",
    "    ner_tag_index = {tag: i for i, tag in enumerate(sorted(ner_tags))}\n",
    "    return ner_tag_index\n",
    "\n",
    "\n",
    "ner_iden = get_unique_pos(all_ner_tags)  # list of tags\n",
    "ner_iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ohv dims\n",
    "ner_idx = ner_iden.values()\n",
    "aa = np.eye(max(ner_idx) + 1)\n",
    "# aa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "First, calculate the document frequency of each token in the entire corpus (training documents + testing documents). The result is a dictionary where each token is a key and its value is the document frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(corpus):\n",
    "    \"\"\"\n",
    "    Computes the document frequency for every token in the corpus.\n",
    "    Returns a dictionary {token: doc_freq, ...}\n",
    "    \"\"\"\n",
    "    document_frequency = {}\n",
    "    for document in corpus:\n",
    "        for token in np.unique(document):\n",
    "            try:\n",
    "                document_frequency[token] += 1\n",
    "            except:\n",
    "                document_frequency[token] = 1\n",
    "    return document_frequency\n",
    "\n",
    "\n",
    "train_corpus = (\n",
    "    train_doc_ques[\"Doc_Tokens\"].tolist() + train_doc_ques[\"Q_Tokens\"].tolist()\n",
    ")\n",
    "test_corpus = test_doc_ques[\"Doc_Tokens\"].tolist() + test_doc_ques[\"Q_Tokens\"].tolist()\n",
    "train_doc_freq = document_frequency(train_corpus)\n",
    "test_doc_freq = document_frequency(test_corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate TF-IDF using the document frequency from above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_tf_idf(corpus, doc_frequency):\n",
    "    \"\"\"\n",
    "    Computes the term frequency inverse document frequency for every token in every document in the corpus.\n",
    "    Returns a list the same shape as the list of tokenized documents except every token is replaced with the tf-idf\n",
    "    for that token.\n",
    "    \"\"\"\n",
    "    tf_idf = {}\n",
    "    tf_idf_list = []\n",
    "    N = len(doc_frequency)\n",
    "    doc_id = 0\n",
    "    for document in corpus:\n",
    "        tf_idf_doc = []\n",
    "        counter = Counter(document)\n",
    "        total_num_words = len(document)\n",
    "        for token in np.unique(document):\n",
    "            tf = counter[token] / total_num_words\n",
    "            df = doc_frequency[token]\n",
    "            idf = math.log(N / (df + 1)) + 1\n",
    "            tf_idf[doc_id, token] = tf * idf\n",
    "        for token in document:\n",
    "            tf_idf_doc.append(tf_idf[doc_id, token])\n",
    "        tf_idf_list.append(tf_idf_doc)\n",
    "        doc_id += 1\n",
    "    return tf_idf_list\n",
    "\n",
    "\n",
    "train_doc_ques[\"Doc_TFIDF\"] = compute_tf_idf(\n",
    "    train_doc_ques[\"Doc_Tokens\"].tolist(), train_doc_freq\n",
    ")\n",
    "train_doc_ques[\"Q_TFIDF\"] = compute_tf_idf(\n",
    "    train_doc_ques[\"Q_Tokens\"].tolist(), train_doc_freq\n",
    ")\n",
    "test_doc_ques[\"Doc_TFIDF\"] = compute_tf_idf(\n",
    "    test_doc_ques[\"Doc_Tokens\"].tolist(), test_doc_freq\n",
    ")\n",
    "test_doc_ques[\"Q_TFIDF\"] = compute_tf_idf(\n",
    "    test_doc_ques[\"Q_Tokens\"].tolist(), test_doc_freq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vectorize(\n",
    "    pos_tagger, ner_tagger, data\n",
    "):  # pass in the unique dict for ner or pos\n",
    "    pos_idx = pos_tagger.values()\n",
    "    pos_ohv = np.eye(max(pos_idx) + 1)  # create the ohv\n",
    "    ner_idx = ner_tagger.values()\n",
    "    ner_ohv = np.eye(max(ner_idx) + 1)\n",
    "\n",
    "    dpos_full_ohv, dner_full_ohv = [], []  # lists to append to\n",
    "    qpos_full_ohv, qner_full_ohv = [], []  # lists to append to\n",
    "\n",
    "    for item in data[\"Doc_POS\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            pos_index_iden = pos_tagger[tag]\n",
    "            sent_ohv.append(pos_ohv[pos_index_iden])\n",
    "        dpos_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Q_POS\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            pos_index_iden = pos_tagger[tag]\n",
    "            sent_ohv.append(pos_ohv[pos_index_iden])\n",
    "        qpos_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Doc_NER\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            ner_index_iden = ner_tagger[tag]\n",
    "            sent_ohv.append(ner_ohv[ner_index_iden])\n",
    "        dner_full_ohv.append(sent_ohv)\n",
    "\n",
    "    for item in data[\"Q_NER\"]:\n",
    "        sent_ohv = []\n",
    "        for word in item:\n",
    "            tag = word[1]\n",
    "            ner_index_iden = ner_tagger[tag]\n",
    "            sent_ohv.append(ner_ohv[ner_index_iden])\n",
    "        qner_full_ohv.append(sent_ohv)\n",
    "\n",
    "    return (dpos_full_ohv, qpos_full_ohv, dner_full_ohv, qner_full_ohv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ohv for doc\n",
    "(\n",
    "    train_doc_pos_ohv,\n",
    "    train_q_pos_ohv,\n",
    "    train_doc_ner_ohv,\n",
    "    train_q_ner_ohv,\n",
    ") = one_hot_vectorize(pos_iden, ner_iden, train_doc_ques)\n",
    "test_doc_pos_ohv, test_q_pos_ohv, test_doc_ner_ohv, test_q_ner_ohv = one_hot_vectorize(\n",
    "    pos_iden, ner_iden, test_doc_ques\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dataframe to just tokens and embeddings:\n",
    "doc_emb_train = train_doc_ques[[\"Doc_Tokens\", \"Doc_Embeddings\", \"Doc_TFIDF\"]]\n",
    "doc_pos_ner = pd.DataFrame({\"Doc_POS\": train_doc_pos_ohv, \"Doc_NER\": train_doc_ner_ohv})\n",
    "doc_emb_train = pd.concat([doc_emb_train, doc_pos_ner], axis=1)\n",
    "\n",
    "q_emb_train = train_doc_ques[[\"Q_Tokens\", \"Q_Embeddings\", \"Q_TFIDF\"]]\n",
    "q_pos_ner = pd.DataFrame({\"Q_POS\": train_q_pos_ohv, \"Q_NER\": train_q_ner_ohv})\n",
    "q_emb_train = pd.concat([q_emb_train, q_pos_ner], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb_test = test_doc_ques[[\"Doc_Tokens\", \"Doc_Embeddings\", \"Doc_TFIDF\"]]\n",
    "doc_pos_ner = pd.DataFrame({\"Doc_POS\": test_doc_pos_ohv, \"Doc_NER\": test_doc_ner_ohv})\n",
    "doc_emb_test = pd.concat([doc_emb_test, doc_pos_ner], axis=1)\n",
    "\n",
    "q_emb_test = test_doc_ques[[\"Q_Tokens\", \"Q_Embeddings\", \"Q_TFIDF\"]]\n",
    "q_pos_ner = pd.DataFrame({\"Q_POS\": test_q_pos_ohv, \"Q_NER\": test_q_ner_ohv})\n",
    "q_emb_test = pd.concat([q_emb_test, q_pos_ner], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (Doc and Qn)\n",
    "\n",
    "The embeddings of the questions and answers of the train and test set can be found here:\n",
    "\n",
    "-   Train Document - doc_emb_train\n",
    "-   Train Q - q_emb_train\n",
    "-   Test Document - doc_emb_test\n",
    "-   Test Q - q_emb_test\n",
    "\n",
    "The max_document size is 1675 and max_question size is 23.\n",
    "Combine all the embeddings into a full array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_array(data, data_type=\"Document\"):\n",
    "    num_vec_length = 156\n",
    "    max_doc = 1675\n",
    "    max_qn = 23\n",
    "    zero_vec = np.zeros(156)\n",
    "\n",
    "    if data_type == \"Document\":\n",
    "        full_vec = []  # create a list for list of list for document\n",
    "        for dat in range(len(data)):  # go through each line\n",
    "            doc_ques = data.loc[dat]  # document data\n",
    "            v = []  # create list to each word\n",
    "            for j in range(len(doc_ques.iloc[0])):\n",
    "                vn = []  # list of concat word embeddings\n",
    "                vn.append(doc_ques.iloc[1][j].tolist())  # Word2Vec\n",
    "                vn.append(doc_ques.iloc[2][j])  # TF-IDF\n",
    "                vn.append(doc_ques.iloc[3][j].tolist())  # POS\n",
    "                vn.append(doc_ques.iloc[4][j].tolist())  # NER\n",
    "                flatten = [\n",
    "                    item\n",
    "                    for sublist in vn\n",
    "                    for item in (sublist if isinstance(sublist, list) else [sublist])\n",
    "                ]\n",
    "                v.append(flatten)\n",
    "            while len(v) < max_doc:\n",
    "                v.append(zero_vec)\n",
    "            full_vec.append(v)\n",
    "\n",
    "    if data_type == \"Question\":\n",
    "        full_vec = []  # create a list for list of list for document\n",
    "        for dat in range(len(data)):  # go through each line\n",
    "            doc_ques = data.loc[dat]  # document data\n",
    "            v = []  # create list to each word\n",
    "            for j in range(len(doc_ques.iloc[0])):\n",
    "                vn = []  # list of concat word embeddings\n",
    "                vn.append(doc_ques.iloc[1][j].tolist())  # Word2Vec\n",
    "                vn.append(doc_ques.iloc[2][j])  # TF-IDF\n",
    "                vn.append(doc_ques.iloc[3][j].tolist())  # POS\n",
    "                vn.append(doc_ques.iloc[4][j].tolist())  # NER\n",
    "                flatten = [\n",
    "                    item\n",
    "                    for sublist in vn\n",
    "                    for item in (sublist if isinstance(sublist, list) else [sublist])\n",
    "                ]\n",
    "                v.append(flatten)\n",
    "            while len(v) < max_qn:\n",
    "                v.append(zero_vec)\n",
    "            full_vec.append(v)\n",
    "    return full_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Test Documents to pass in, takes about a min\n",
    "final_doc_train = np.stack(full_array(doc_emb_train, data_type=\"Document\"))\n",
    "final_doc_test = np.stack(full_array(doc_emb_test, data_type=\"Document\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Test Questions to pass in, takes about a few seconds\n",
    "final_qn_train = np.stack(full_array(q_emb_train, data_type=\"Question\"))\n",
    "final_qn_test = np.stack(full_array(q_emb_test, data_type=\"Question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels):\n",
    "    check = []\n",
    "    for i in labels:\n",
    "        if len(i) < 1675:\n",
    "            while len(i) < 1675:\n",
    "                i.append(\"N\")\n",
    "            check.append(i)\n",
    "        else:\n",
    "            check.append(i)\n",
    "    return check\n",
    "\n",
    "\n",
    "tr_labels = np.array(convert_labels(train_doc_ans_labels))\n",
    "ts_labels = np.array(convert_labels(test_doc_ans_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we found that the sequence length of the documents can get quite large, which might introduce a lot of noise into the model with paddings. One alternative to reduce this noise is to perhaps truncate the sequences down to just over the median for the documents. We also need to do this for the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max Seq Length is 1675, Median is 181.0, Number of lines is 630)',\n",
       " 'Max Seq Length is 924, Median is 182.0, Number of lines is 2117)',\n",
       " 'Max Seq Length is 19, Median is 7.0, Number of lines is 630)',\n",
       " 'Max Seq Length is 23, Median is 7.0, Number of lines is 2117)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_max_length(test_doc_ques[\"Doc_Embeddings\"]), find_max_length(\n",
    "    train_doc_ques[\"Doc_Embeddings\"]\n",
    "), find_max_length(test_doc_ques[\"Q_Embeddings\"]), find_max_length(\n",
    "    train_doc_ques[\"Q_Embeddings\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate the embeddings and the labels to 200\n",
    "\n",
    "\n",
    "def truncate(data, labels, max_seq=200):\n",
    "    data = data[:, :max_seq, :]\n",
    "    labels = labels[:, :max_seq]\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "final_doc_train, tr_labels = truncate(final_doc_train, tr_labels)\n",
    "final_doc_test, ts_labels = truncate(final_doc_test, ts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final prepared documents are found here:\n",
    "\n",
    "# final_doc_train, tr_labels - doc embeddings and output labels for training\n",
    "# final_doc_test, ts_labels - doc embeddings and output labels for testing\n",
    "# final_qn_train - question embeddings for training\n",
    "# final_qn_test - question embeddings for testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the arrays to a float32, then save those np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to float32 \n",
    "final_doc_train = final_doc_train.astype(\"float32\")\n",
    "final_doc_test = final_doc_test.astype(\"float32\")\n",
    "final_qn_train = final_qn_train.astype(\"float32\")\n",
    "final_qn_test = final_qn_test.astype(\"float32\")\n",
    "\n",
    "# save the np.arrays\n",
    "np.save(\"./cleaneddata/final_doc_train.npy\", final_doc_train)\n",
    "np.save(\"./cleaneddata/final_doc_test.npy\", final_doc_test)\n",
    "np.save(\"./cleaneddata/final_qn_train.npy\", final_qn_train)\n",
    "np.save(\"./cleaneddata/final_qn_test.npy\", final_qn_test)\n",
    "np.save(\"./cleaneddata/tr_labels.npy\", tr_labels)\n",
    "np.save(\"./cleaneddata/ts_labels.npy\", ts_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
